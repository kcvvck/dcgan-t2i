{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\nfrom __future__ import unicode_literals\n\n\nimport torch.utils.data as data\nfrom PIL import Image\nimport PIL\nimport os\nimport os.path\nimport pickle\nimport random\nimport numpy as np\nimport pandas as pd\nimport torchvision.transforms as transforms\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.backends.cudnn as cudnn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import StepLR\nimport torch.utils.data\nimport torchvision.datasets as dset\nimport torchvision.transforms as transforms\nimport torchvision.utils as vutils\nfrom torch.optim.lr_scheduler import StepLR\nfrom torch.autograd import Variable\n\nfrom datetime import datetime\nimport random\n","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:53:53.869222Z","iopub.execute_input":"2023-04-09T03:53:53.869870Z","iopub.status.idle":"2023-04-09T03:53:57.173010Z","shell.execute_reply.started":"2023-04-09T03:53:53.869811Z","shell.execute_reply":"2023-04-09T03:53:57.171935Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class TextDataset(data.Dataset):\n    def __init__(self, data_dir, data_dir2, split='train', embedding_type='skip-thought',\n                 imsize=64, transform=None, target_transform=None):\n\n        self.transform = transform\n        self.target_transform = target_transform\n        self.imsize = imsize\n        self.data = []\n        self.data_dir = data_dir\n        self.bbox = self.load_bbox()\n        split_dir = os.path.join(data_dir2, split)\n\n        self.filenames = self.load_filenames(split_dir)\n        self.embeddings = self.load_embedding(split_dir, embedding_type)\n        self.captions = self.load_all_captions()\n\n    def get_img(self, img_path, bbox):\n        img = Image.open(img_path).convert('RGB')\n        width, height = img.size\n        if bbox is not None:\n            R = int(np.maximum(bbox[2], bbox[3]) * 0.75)\n            center_x = int((2 * bbox[0] + bbox[2]) / 2)\n            center_y = int((2 * bbox[1] + bbox[3]) / 2)\n            y1 = np.maximum(0, center_y - R)\n            y2 = np.minimum(height, center_y + R)\n            x1 = np.maximum(0, center_x - R)\n            x2 = np.minimum(width, center_x + R)\n            img = img.crop([x1, y1, x2, y2])\n        load_size = int(self.imsize * 76 / 64)\n        img = img.resize((load_size, load_size), PIL.Image.Resampling.BILINEAR)\n        if self.transform is not None:\n            img = self.transform(img)\n        return img\n\n    def load_bbox(self):\n        data_dir = self.data_dir\n        bbox_path = os.path.join(data_dir, 'CUB_200_2011/bounding_boxes.txt')\n        df_bounding_boxes = pd.read_csv(bbox_path,\n                                        delim_whitespace=True,\n                                        header=None).astype(int)\n        #\n        filepath = os.path.join(data_dir, 'CUB_200_2011/images.txt')\n        df_filenames = \\\n            pd.read_csv(filepath, delim_whitespace=True, header=None)\n        filenames = df_filenames[1].tolist()\n        print('Total filenames: ', len(filenames), filenames[0])\n        #\n        filename_bbox = {img_file[:-4]: [] for img_file in filenames}\n        numImgs = len(filenames)\n        for i in range(0, numImgs):\n            # bbox = [x-left, y-top, width, height]\n            bbox = df_bounding_boxes.iloc[i][1:].tolist()\n\n            key = filenames[i][:-4]\n            if \"_rgb\" in key:\n                key = key.replace(\"_rgb\", \"\" ).strip()\n            filename_bbox[key] = bbox\n        #\n        return filename_bbox\n\n    def load_all_captions(self):\n        caption_dict = {}\n        for key in self.filenames:\n            if \"_rgb\" in key:\n                key = key.replace(\"_rgb\", \"\" ).strip()\n            caption_name = '%s/cvpr2016_cub/text_c10/%s.txt' % (self.data_dir, key)\n            captions = self.load_captions(caption_name)\n            caption_dict[key] = captions\n        return caption_dict\n\n    def load_captions(self, caption_name):\n        cap_path = caption_name\n        with open(cap_path, \"r\") as f:\n            captions = f.read().split('\\n')\n        captions = [cap.replace(\"\\ufffd\\ufffd\", \" \")\n                    for cap in captions if len(cap) > 0]\n        return captions\n\n    def load_embedding(self, data_dir, embedding_type):\n        if embedding_type == 'cnn-rnn':\n            embedding_filename = '/char-CNN-RNN-embeddings.pickle'\n        elif embedding_type == 'cnn-gru':\n            embedding_filename = '/char-CNN-GRU-embeddings.pickle'\n        elif embedding_type == 'skip-thought':\n            embedding_filename = '/skip-thought-embeddings.pickle'\n\n        with open(data_dir + embedding_filename, 'rb') as f:\n            embeddings = pickle.load(f)\n            embeddings = np.array(embeddings)\n            # embedding_shape = [embeddings.shape[-1]]\n            print('embeddings: ', embeddings.shape)\n        return embeddings\n\n    def load_filenames(self, data_dir):\n        filepath = os.path.join(data_dir, 'filenames.pickle')\n        with open(filepath, 'rb') as f:\n            filenames = pickle.load(f)\n        print('Load filenames from: %s (%d)' % (filepath, len(filenames)))\n        return filenames\n\n    def __getitem__(self, index):\n        key = self.filenames[index]\n        if \"_rgb\" in key:\n            key = key.replace(\"_rgb\", \"\" ).strip()\n        if self.bbox is not None:\n            bbox = self.bbox[key]\n            data_dir = '%s/CUB_200_2011' % self.data_dir\n        else:\n            bbox = None\n            data_dir = self.data_dir\n\n        captions = self.captions[key]\n        embeddings = self.embeddings[index, :, :]\n        img_name = '%s/images/%s.jpg' % (data_dir, key)\n        img = self.get_img(img_name, bbox)\n\n        rand_ix = random.randint(0, embeddings.shape[0]-1)\n        embedding = embeddings[rand_ix, :]\n        if self.target_transform is not None:\n            embedding = self.target_transform(embedding)\n        return img, embedding,captions[rand_ix]\n\n    def __len__(self):\n        return len(self.filenames)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:53:57.178973Z","iopub.execute_input":"2023-04-09T03:53:57.181543Z","iopub.status.idle":"2023-04-09T03:53:57.245230Z","shell.execute_reply.started":"2023-04-09T03:53:57.181501Z","shell.execute_reply":"2023-04-09T03:53:57.244186Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"ngpu = 1\nnz = 100\nngf = 64\nndf = 64\nnc = 3\nnt = 256\nnte = 4800\n\nlr = 0.0002\nniter = 400\nworkers = 2\nbeta1 = 0.5\nimageSize = 64\nBATCH_SIZE = 32\n\nworking_dir = \"/kaggle/working/\"\nsnapshots = os.path.join(working_dir, 'snapshots')\nmodels_path = os.path.join(working_dir, 'models')\n","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:53:57.251309Z","iopub.execute_input":"2023-04-09T03:53:57.258924Z","iopub.status.idle":"2023-04-09T03:53:57.267807Z","shell.execute_reply.started":"2023-04-09T03:53:57.258886Z","shell.execute_reply":"2023-04-09T03:53:57.266861Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"image_transform = transforms.Compose([\n    transforms.RandomCrop(imageSize),\n    transforms.RandomHorizontalFlip(),\n    transforms.ToTensor(),\n    transforms.Normalize((0, 0, 0), (1, 1, 1))\n])","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:53:57.274626Z","iopub.execute_input":"2023-04-09T03:53:57.278054Z","iopub.status.idle":"2023-04-09T03:53:57.287692Z","shell.execute_reply.started":"2023-04-09T03:53:57.278018Z","shell.execute_reply":"2023-04-09T03:53:57.286745Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"dataroot = \"/kaggle/input/cub2002011\"\ndataroot2 = \"/kaggle/input/birdsdata\"","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:53:57.293652Z","iopub.execute_input":"2023-04-09T03:53:57.296228Z","iopub.status.idle":"2023-04-09T03:53:57.308492Z","shell.execute_reply.started":"2023-04-09T03:53:57.296192Z","shell.execute_reply":"2023-04-09T03:53:57.307559Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"if not os.path.exists(training_binary_path):\n    os.makedirs(training_binary_path)\n\nif not os.path.exists(logs_files):\n    os.makedirs(logs_files)\n\nif not os.path.exists(snapshots):\n    os.makedirs(snapshots)\n\nif not os.path.exists(models_path):\n    os.makedirs(models_path)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:53:57.310655Z","iopub.execute_input":"2023-04-09T03:53:57.313575Z","iopub.status.idle":"2023-04-09T03:53:57.323403Z","shell.execute_reply.started":"2023-04-09T03:53:57.313539Z","shell.execute_reply":"2023-04-09T03:53:57.322382Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2023-03-21T02:53:21.695252Z","iopub.execute_input":"2023-03-21T02:53:21.695630Z","iopub.status.idle":"2023-03-21T02:53:21.705082Z","shell.execute_reply.started":"2023-03-21T02:53:21.695592Z","shell.execute_reply":"2023-03-21T02:53:21.703985Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"manualSeed = 42\nprint(\"Random Seed: \", manualSeed)\nrandom.seed(manualSeed)\ntorch.manual_seed(manualSeed)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:53:57.325596Z","iopub.execute_input":"2023-04-09T03:53:57.327795Z","iopub.status.idle":"2023-04-09T03:53:57.352192Z","shell.execute_reply.started":"2023-04-09T03:53:57.327760Z","shell.execute_reply":"2023-04-09T03:53:57.350472Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Random Seed:  42\n","output_type":"stream"},{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"<torch._C.Generator at 0x7b872fa0a7d0>"},"metadata":{}}]},{"cell_type":"code","source":"cuda = True\ncudnn.benchmark = True\n\nif torch.cuda.is_available() and not cuda:\n    print(\n    \"WARNING: You have a CUDA device, so you should probably run with --cuda\"\n    )","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:53:57.357484Z","iopub.execute_input":"2023-04-09T03:53:57.358742Z","iopub.status.idle":"2023-04-09T03:53:57.459930Z","shell.execute_reply.started":"2023-04-09T03:53:57.358707Z","shell.execute_reply":"2023-04-09T03:53:57.456772Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# custom weights initialization called on netG and netD\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        m.weight.data.normal_(0.0, 0.02)\n    elif classname.find('BatchNorm') != -1:\n        m.weight.data.normal_(1.0, 0.02)\n        m.bias.data.fill_(0)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:53:57.471440Z","iopub.execute_input":"2023-04-09T03:53:57.471813Z","iopub.status.idle":"2023-04-09T03:53:57.489865Z","shell.execute_reply.started":"2023-04-09T03:53:57.471780Z","shell.execute_reply":"2023-04-09T03:53:57.487080Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"class _netG(nn.Module):\n    def __init__(self, ngpu, nz, ngf, nc, nte, nt):\n        super(_netG, self).__init__()\n        self.nt = nt\n        self.ngpu = ngpu\n        self.main = nn.Sequential(\n            # input is Z, going into a convolution\n            nn.ConvTranspose2d(nz + nt, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d(ngf * 8),\n            # nn.ReLU(True),\n            # state size. (ngf*8) x 4 x 4\n\n            nn.Conv2d(ngf*8,ngf*2,1,1),\n            nn.Dropout2d(inplace=True),            \n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            # nn.SELU(True),\n\n            nn.Conv2d(ngf*2,ngf*2,3,1,1),\n            nn.Dropout2d(inplace=True),            \n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            # nn.SELU(True),\n\n            nn.Conv2d(ngf*2,ngf*8,3,1,1),\n            nn.Dropout2d(inplace=True),            \n            nn.BatchNorm2d(ngf * 8),\n            nn.ReLU(inplace=True),\n            # nn.SELU(True),\n\n\n            nn.ConvTranspose2d(ngf * 8, ngf * 4, 4, 2, 1, bias=False),   \n            nn.BatchNorm2d(ngf * 4),\n            # nn.ReLU(True),\n            # state size. (ngf*4) x 8 x 8\n            \n            nn.Conv2d(ngf*4,ngf,1,1),\n            nn.Dropout2d(inplace=True),            \n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # nn.SELU(True),\n\n            nn.Conv2d(ngf,ngf,3,1,1),\n            nn.Dropout2d(inplace=True),            \n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # nn.SELU(True),\n\n            nn.Conv2d(ngf,ngf*4,3,1,1),\n            nn.Dropout2d(inplace=True),            \n            nn.BatchNorm2d(ngf * 4),\n            nn.ReLU(True),\n            # nn.SELU(True),            \n            \n            nn.ConvTranspose2d(ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf * 2),\n            nn.ReLU(True),\n            # nn.SELU(True),\n            \n            # state size. (ngf*2) x 16 x 16\n            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ngf),\n            nn.ReLU(True),\n            # nn.SELU(True),\n\n            # state size. (ngf) x 32 x 32\n            nn.ConvTranspose2d(    ngf,      nc, 4, 2, 1, bias=False),\n            nn.Tanh()\n            # state size. (nc) x 64 x 64\n        )\n\n        self.encode_text = nn.Sequential(\n            nn.Linear(nte, nt), nn.LeakyReLU(0.2, inplace=True))\n\n    def forward(self, input, text_embedding):\n        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n            encoded_text = nn.parallel.data_parallel(self.encode_text, text_embedding, )\n            input_new = torch.cat((input, encoded_text))\n            output = nn.parallel.data_parallel(self.main,input_new, range(self.ngpu))\n        else:\n            encoded_text = self.encode_text(text_embedding).view(-1,self.nt,1,1)\n            output = self.main(torch.cat((input, encoded_text), 1))\n        return output\n","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:53:57.498658Z","iopub.execute_input":"2023-04-09T03:53:57.501283Z","iopub.status.idle":"2023-04-09T03:53:57.546530Z","shell.execute_reply.started":"2023-04-09T03:53:57.501247Z","shell.execute_reply":"2023-04-09T03:53:57.545533Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class _netD(nn.Module):\n    def __init__(self, ngpu, nc, ndf, nte, nt):\n        super(_netD, self).__init__()\n        self.ngpu = ngpu\n        self.nt = nt\n        self.nte = nte\n        self.main = nn.Sequential(\n            # input is (nc) x 64 x 64\n            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf) x 32 x 32\n            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*2) x 16 x 16\n            nn.Conv2d(ndf * 2, ndf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 4),\n            nn.LeakyReLU(0.2, inplace=True),\n            # state size. (ndf*4) x 8 x 8\n            nn.Conv2d(ndf * 4, ndf * 8, 4, 2, 1, bias=False),\n            nn.BatchNorm2d(ndf * 8),\n\n            nn.Conv2d(ndf*8,ndf*2,1,1),\n            # nn.Dropout2d(inplace=True),            \n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n\n            nn.Conv2d(ndf*2,ndf*2,3,1,1),\n            # nn.Dropout2d(inplace=True),            \n            nn.BatchNorm2d(ndf * 2),\n            nn.LeakyReLU(0.2, inplace=True),\n\n            nn.Conv2d(ndf*2,ndf*8,3,1,1),\n            # nn.Dropout2d(inplace=True),            \n            nn.BatchNorm2d(ndf * 8),\n            nn.LeakyReLU(0.2, inplace=True))\n\n        # state size. (ndf*8) x 4 x 4\n\n        self.encode_text = nn.Sequential(\n            nn.Linear(nte, nt),\n            nn.LeakyReLU(0.2, inplace=True)\n\n        )\n\n        self.concat_image_n_text = nn.Sequential(\n            nn.Conv2d(ndf * 8 + nt, ndf * 8, 1, 1, 0, bias=False), ## TODO: Might want to change the kernel size and stride\n            nn.BatchNorm2d(ndf*8),\n            nn.LeakyReLU(0.2,inplace=True),\n            nn.Conv2d(ndf * 8, 1, 4, 1, 0, bias=False),\n            nn.Sigmoid()\n        )\n\n    def forward(self, input, text_embedding):\n        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n            encoded_img = nn.parallel.data_parallel(self.main, input,\n                                               range(self.ngpu))\n            encoded_text = nn.parallel.data_parallel(self.encode_text, text_embedding, range(self.ngpu))\n\n        else:\n            encoded_img = self.main(input)\n            encoded_text = self.encode_text(text_embedding)\n            encoded_text = encoded_text.view(-1, self.nt, 1,1)\n            encoded_text = encoded_text.repeat(1, 1, 4, 4) ## can also directly expand, look into the syntax\n            output = self.concat_image_n_text(torch.cat((encoded_img, encoded_text),1))\n\n        return output.view(-1, 1).squeeze(1)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:53:57.552386Z","iopub.execute_input":"2023-04-09T03:53:57.557727Z","iopub.status.idle":"2023-04-09T03:53:57.605676Z","shell.execute_reply.started":"2023-04-09T03:53:57.557657Z","shell.execute_reply":"2023-04-09T03:53:57.604322Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"saved_gen = '/kaggle/input/birdsdata/models_v2/models/netG_epoch_600.pth'\nsaved_dis = '/kaggle/input/birdsdata/models_v2/models/netD_epoch_600.pth'","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:53:57.612976Z","iopub.execute_input":"2023-04-09T03:53:57.615927Z","iopub.status.idle":"2023-04-09T03:53:57.628557Z","shell.execute_reply.started":"2023-04-09T03:53:57.615882Z","shell.execute_reply":"2023-04-09T03:53:57.624029Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"netG = _netG(ngpu, nz, ngf, nc, nte, nt)\nnetG.apply(weights_init)\nnetG.load_state_dict(torch.load(saved_gen))\nprint(netG)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:53:57.633433Z","iopub.execute_input":"2023-04-09T03:53:57.636185Z","iopub.status.idle":"2023-04-09T03:54:01.302792Z","shell.execute_reply.started":"2023-04-09T03:53:57.636139Z","shell.execute_reply":"2023-04-09T03:54:01.301523Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"_netG(\n  (main): Sequential(\n    (0): ConvTranspose2d(356, 512, kernel_size=(4, 4), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n    (3): Dropout2d(p=0.5, inplace=True)\n    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (5): ReLU(inplace=True)\n    (6): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): Dropout2d(p=0.5, inplace=True)\n    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (9): ReLU(inplace=True)\n    (10): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): Dropout2d(p=0.5, inplace=True)\n    (12): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (13): ReLU(inplace=True)\n    (14): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (16): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n    (17): Dropout2d(p=0.5, inplace=True)\n    (18): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (19): ReLU(inplace=True)\n    (20): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (21): Dropout2d(p=0.5, inplace=True)\n    (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (23): ReLU(inplace=True)\n    (24): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (25): Dropout2d(p=0.5, inplace=True)\n    (26): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (27): ReLU(inplace=True)\n    (28): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (29): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (30): ReLU(inplace=True)\n    (31): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (32): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (33): ReLU(inplace=True)\n    (34): ConvTranspose2d(64, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (35): Tanh()\n  )\n  (encode_text): Sequential(\n    (0): Linear(in_features=4800, out_features=256, bias=True)\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"netD = _netD(ngpu, nc, ndf, nte, nt)\nnetD.apply(weights_init)\nnetD.load_state_dict(torch.load(saved_dis))\nprint(netD)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:54:01.304375Z","iopub.execute_input":"2023-04-09T03:54:01.305421Z","iopub.status.idle":"2023-04-09T03:54:01.663394Z","shell.execute_reply.started":"2023-04-09T03:54:01.305381Z","shell.execute_reply":"2023-04-09T03:54:01.662243Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"_netD(\n  (main): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n    (2): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): LeakyReLU(negative_slope=0.2, inplace=True)\n    (5): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (7): LeakyReLU(negative_slope=0.2, inplace=True)\n    (8): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n    (9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (10): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (12): LeakyReLU(negative_slope=0.2, inplace=True)\n    (13): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (14): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (15): LeakyReLU(negative_slope=0.2, inplace=True)\n    (16): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (18): LeakyReLU(negative_slope=0.2, inplace=True)\n  )\n  (encode_text): Sequential(\n    (0): Linear(in_features=4800, out_features=256, bias=True)\n    (1): LeakyReLU(negative_slope=0.2, inplace=True)\n  )\n  (concat_image_n_text): Sequential(\n    (0): Conv2d(768, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): LeakyReLU(negative_slope=0.2, inplace=True)\n    (3): Conv2d(512, 1, kernel_size=(4, 4), stride=(1, 1), bias=False)\n    (4): Sigmoid()\n  )\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = nn.BCELoss()\n\ninput = torch.FloatTensor(BATCH_SIZE, 3, imageSize, imageSize)\nnoise = torch.FloatTensor(BATCH_SIZE, nz, 1, 1)\nfixed_noise = torch.FloatTensor(BATCH_SIZE, nz, 1, 1).normal_(0, 1)\nlabel = torch.FloatTensor(BATCH_SIZE)\nreal_label = 1\nfake_label = 0","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:54:01.664865Z","iopub.execute_input":"2023-04-09T03:54:01.665904Z","iopub.status.idle":"2023-04-09T03:54:01.672887Z","shell.execute_reply.started":"2023-04-09T03:54:01.665864Z","shell.execute_reply":"2023-04-09T03:54:01.671895Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"if cuda:\n    netD.cuda()\n    netG.cuda()\n    criterion.cuda()\n    input, label = input.cuda(), label.cuda()\n    noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n\nfixed_noise = Variable(fixed_noise)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:54:01.674507Z","iopub.execute_input":"2023-04-09T03:54:01.674896Z","iopub.status.idle":"2023-04-09T03:54:01.705052Z","shell.execute_reply.started":"2023-04-09T03:54:01.674859Z","shell.execute_reply":"2023-04-09T03:54:01.704142Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train","metadata":{}},{"cell_type":"code","source":"train_dataset = TextDataset(dataroot, dataroot2, transform=image_transform)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T11:12:51.280057Z","iopub.execute_input":"2023-03-22T11:12:51.280525Z","iopub.status.idle":"2023-03-22T11:14:28.637922Z","shell.execute_reply.started":"2023-03-22T11:12:51.280482Z","shell.execute_reply":"2023-03-22T11:14:28.636874Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\nLoad filenames from: /kaggle/input/birdsdata/train/filenames.pickle (8251)\nembeddings:  (8251, 10, 4800)\n","output_type":"stream"}]},{"cell_type":"code","source":"train_dataloader = torch.utils.data.DataLoader(\n                    train_dataset,\n                    batch_size=BATCH_SIZE,\n                    shuffle=True,\n                    num_workers=int(workers))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T02:53:21.669633Z","iopub.execute_input":"2023-03-21T02:53:21.670696Z","iopub.status.idle":"2023-03-21T02:53:21.676696Z","shell.execute_reply.started":"2023-03-21T02:53:21.670653Z","shell.execute_reply":"2023-03-21T02:53:21.675191Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"optimizerD = optim.Adam(\n  netD.parameters(), lr=lr, betas=(beta1, 0.999))\noptimizerG = optim.Adam(\n  netG.parameters(), lr=lr, betas=(beta1, 0.999))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T02:53:25.914425Z","iopub.execute_input":"2023-03-21T02:53:25.915127Z","iopub.status.idle":"2023-03-21T02:53:25.921304Z","shell.execute_reply.started":"2023-03-21T02:53:25.915089Z","shell.execute_reply":"2023-03-21T02:53:25.920282Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import csv\n\nheader = [\"epoch\", \"g_loss\", \"d_loss\", \"d_loss_fake\", \"d_loss_real\"]\nwith open(f\"{snapshots}/logs.csv\", \"w+\") as f:\n    writer = csv.writer(f)\n    writer.writerow(header)","metadata":{"execution":{"iopub.status.busy":"2023-03-21T02:53:25.922945Z","iopub.execute_input":"2023-03-21T02:53:25.923328Z","iopub.status.idle":"2023-03-21T02:53:25.932366Z","shell.execute_reply.started":"2023-03-21T02:53:25.923293Z","shell.execute_reply":"2023-03-21T02:53:25.931453Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"for epoch in range(1, niter + 1):\n    loss_d = 0\n    loss_g = 0\n    d_loss_fake_ = 0\n    d_loss_real_ = 0\n    if epoch % 75 == 0:\n        optimizerG.param_groups[0]['lr'] /= 2\n        optimizerD.param_groups[0]['lr'] /= 2\n    for i, data in enumerate(train_dataloader, 0):\n        ############################\n        # (1) Update D network: maximize log(D(x)) + log(1 - D(G(z)))\n        ###########################\n        # train with real\n        netD.zero_grad()\n        real_cpu, text_embedding, _ = data\n        batch_size = real_cpu.size(0)\n        text_embedding = Variable(text_embedding)\n\n        if cuda:\n            real_cpu = real_cpu.cuda()\n            text_embedding = text_embedding.cuda()\n\n        input.resize_as_(real_cpu).copy_(real_cpu)\n        label.resize_(batch_size).fill_(real_label)\n        inputv = Variable(input)\n        labelv = Variable(label)\n\n        output = netD(inputv, text_embedding)\n        errD_real = criterion(output, labelv)  ##\n        errD_real.backward()\n        D_x = output.data.mean()\n\n        ### calculate errD_wrong\n        inputv = torch.cat((inputv[1:], inputv[:1]), 0)\n        output = netD(inputv, text_embedding)\n        errD_wrong = criterion(output, labelv) * 0.5\n        errD_wrong.backward()\n\n        # train with fake\n        noise.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n        noisev = Variable(noise)\n        fake = netG(noisev, text_embedding)\n        labelv = Variable(label.fill_(fake_label))\n        output = netD(fake.detach(), text_embedding)\n        errD_fake = criterion(output, labelv) * 0.5\n        errD_fake.backward()\n        D_G_z1 = output.data.mean()\n\n        errD = errD_real + errD_fake + errD_wrong\n        # errD.backward()\n        optimizerD.step()\n\n        ############################\n        # (2) Update G network: maximize log(D(G(z)))\n        ###########################\n        netG.zero_grad()\n        labelv = Variable(label.fill_(\n            real_label))  # fake labels are real for generator cost\n        output = netD(fake, text_embedding)\n        errG = criterion(output, labelv)  ##\n        errG.backward()\n        D_G_z2 = output.data.mean()\n        optimizerG.step()\n        loss_d += errD.data\n        loss_g += errG.data\n        d_loss_fake_ += D_G_z1/D_G_z2\n        d_loss_real_ += D_x\n        \n        if i % 100 == 0:\n            vutils.save_image(\n                real_cpu, '%s/real_samples.png' % snapshots, normalize=True)\n            fake = netG(fixed_noise, text_embedding)\n            vutils.save_image(\n                fake.data,\n                '%s/fake_samples_epoch_%03d.png' % (snapshots, epoch),\n                normalize=True)\n    loss_d_ = loss_d/len(train_dataloader)\n    loss_g_ = loss_g/len(train_dataloader)\n    d_loss_fake__ = d_loss_fake_/len(train_dataloader)\n    d_loss_real__ = d_loss_real_/len(train_dataloader)\n    print(\n        '[%d/%d] Loss_D: %.4f Loss_G: %.4f D(x): %.4f D(G(z)): %.4f'\n        % (epoch, niter, loss_d_,\n        loss_g_, d_loss_real__, d_loss_fake__))\n    with open(f\"{snapshots}/logs.csv\", \"a+\") as logs_file:\n        writer = csv.writer(logs_file)\n        writer.writerow([epoch,loss_g_,loss_d_,d_loss_fake__,d_loss_real__])\n\n    # do checkpointing\n    if epoch % 20 == 0:\n        torch.save(netG.state_dict(), '%s/netG_epoch_%d.pth' % (models_path,\n                                                                epoch))\n        torch.save(netD.state_dict(), '%s/netD_epoch_%d.pth' % (models_path,\n                                                                epoch))","metadata":{"execution":{"iopub.status.busy":"2023-03-21T02:53:25.933867Z","iopub.execute_input":"2023-03-21T02:53:25.934668Z","iopub.status.idle":"2023-03-21T07:37:07.329950Z","shell.execute_reply.started":"2023-03-21T02:53:25.934632Z","shell.execute_reply":"2023-03-21T07:37:07.327763Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"[1/400] Loss_D: 0.3578 Loss_G: 6.8431 D(x): 0.9553 D(G(z)): 3469935.2500\n[2/400] Loss_D: 0.4028 Loss_G: 5.1199 D(x): 0.9472 D(G(z)): 1099.7072\n[3/400] Loss_D: 0.1900 Loss_G: 5.8324 D(x): 0.9672 D(G(z)): 562.7416\n[4/400] Loss_D: 0.2282 Loss_G: 6.1631 D(x): 0.9697 D(G(z)): 4870.7666\n[5/400] Loss_D: 0.1599 Loss_G: 6.5995 D(x): 0.9727 D(G(z)): 21517.8945\n[6/400] Loss_D: 0.3181 Loss_G: 5.8115 D(x): 0.9534 D(G(z)): 7240.9951\n[7/400] Loss_D: 0.2632 Loss_G: 5.4497 D(x): 0.9624 D(G(z)): 1328.9270\n[8/400] Loss_D: 0.4164 Loss_G: 5.2738 D(x): 0.9535 D(G(z)): 2290.0430\n[9/400] Loss_D: 0.3586 Loss_G: 4.9950 D(x): 0.9460 D(G(z)): 449.2559\n[10/400] Loss_D: 0.1363 Loss_G: 6.1112 D(x): 0.9721 D(G(z)): 2217.8484\n[11/400] Loss_D: 0.2070 Loss_G: 6.6967 D(x): 0.9786 D(G(z)): 74713.7422\n[12/400] Loss_D: 0.3303 Loss_G: 5.5383 D(x): 0.9550 D(G(z)): 5560.7246\n[13/400] Loss_D: 0.3503 Loss_G: 5.2873 D(x): 0.9486 D(G(z)): 708.8704\n[14/400] Loss_D: 0.2656 Loss_G: 5.3297 D(x): 0.9593 D(G(z)): 1766.7609\n[15/400] Loss_D: 0.3867 Loss_G: 4.9238 D(x): 0.9481 D(G(z)): 100.7941\n[16/400] Loss_D: 0.1892 Loss_G: 5.5210 D(x): 0.9663 D(G(z)): 1666.9794\n[17/400] Loss_D: 0.2866 Loss_G: 5.7584 D(x): 0.9525 D(G(z)): 3798.5139\n[18/400] Loss_D: 0.2238 Loss_G: 5.6276 D(x): 0.9686 D(G(z)): 497.5168\n[19/400] Loss_D: 0.2465 Loss_G: 5.4412 D(x): 0.9611 D(G(z)): 337.2135\n[20/400] Loss_D: 0.1964 Loss_G: 6.1790 D(x): 0.9653 D(G(z)): 19392.7891\n[21/400] Loss_D: 0.3143 Loss_G: 5.6006 D(x): 0.9556 D(G(z)): 516.7805\n[22/400] Loss_D: 0.2424 Loss_G: 5.8359 D(x): 0.9591 D(G(z)): 1438.3807\n[23/400] Loss_D: 0.2516 Loss_G: 5.5360 D(x): 0.9598 D(G(z)): 905.7690\n[24/400] Loss_D: 0.1602 Loss_G: 5.8632 D(x): 0.9705 D(G(z)): 667.3757\n[25/400] Loss_D: 0.3474 Loss_G: 5.5139 D(x): 0.9541 D(G(z)): 2678.7153\n[26/400] Loss_D: 0.2983 Loss_G: 5.1716 D(x): 0.9591 D(G(z)): 393.8649\n[27/400] Loss_D: 0.1839 Loss_G: 5.5422 D(x): 0.9682 D(G(z)): 2484.5039\n[28/400] Loss_D: 0.2310 Loss_G: 5.7447 D(x): 0.9651 D(G(z)): 535.2324\n[29/400] Loss_D: 0.2647 Loss_G: 5.5742 D(x): 0.9593 D(G(z)): 419.1964\n[30/400] Loss_D: 0.2541 Loss_G: 5.6141 D(x): 0.9616 D(G(z)): 980.2582\n[31/400] Loss_D: 0.1715 Loss_G: 5.9842 D(x): 0.9695 D(G(z)): 3192.6738\n[32/400] Loss_D: 0.3820 Loss_G: 5.1574 D(x): 0.9531 D(G(z)): 327.0190\n[33/400] Loss_D: 0.2053 Loss_G: 5.5712 D(x): 0.9661 D(G(z)): 529.0647\n[34/400] Loss_D: 0.1484 Loss_G: 6.0857 D(x): 0.9732 D(G(z)): 4594.9067\n[35/400] Loss_D: 0.1069 Loss_G: 6.1874 D(x): 0.9800 D(G(z)): 819.1997\n[36/400] Loss_D: 0.2717 Loss_G: 5.5173 D(x): 0.9631 D(G(z)): 1216.1044\n[37/400] Loss_D: 0.2629 Loss_G: 5.8664 D(x): 0.9626 D(G(z)): 5280.2949\n[38/400] Loss_D: 0.1669 Loss_G: 5.7754 D(x): 0.9685 D(G(z)): 944.2844\n[39/400] Loss_D: 0.3309 Loss_G: 5.5235 D(x): 0.9560 D(G(z)): 1275.3534\n[40/400] Loss_D: 0.3228 Loss_G: 5.4762 D(x): 0.9533 D(G(z)): 808.7665\n[41/400] Loss_D: 0.2410 Loss_G: 5.3088 D(x): 0.9578 D(G(z)): 367.5719\n[42/400] Loss_D: 0.2105 Loss_G: 5.6379 D(x): 0.9625 D(G(z)): 172.9871\n[43/400] Loss_D: 0.1696 Loss_G: 5.8633 D(x): 0.9718 D(G(z)): 468.6664\n[44/400] Loss_D: 0.1471 Loss_G: 6.0802 D(x): 0.9736 D(G(z)): 3623.1665\n[45/400] Loss_D: 0.2322 Loss_G: 5.9077 D(x): 0.9635 D(G(z)): 8168.0894\n[46/400] Loss_D: 0.1432 Loss_G: 6.0072 D(x): 0.9745 D(G(z)): 1016.0078\n[47/400] Loss_D: 0.2306 Loss_G: 6.1338 D(x): 0.9667 D(G(z)): 5165.9648\n[48/400] Loss_D: 0.1635 Loss_G: 6.0829 D(x): 0.9743 D(G(z)): 776.5262\n[49/400] Loss_D: 0.1588 Loss_G: 6.2239 D(x): 0.9722 D(G(z)): 14997.7158\n[50/400] Loss_D: 0.1969 Loss_G: 6.1665 D(x): 0.9714 D(G(z)): 11216.5771\n[51/400] Loss_D: 0.2626 Loss_G: 6.0000 D(x): 0.9644 D(G(z)): 31708.5859\n[52/400] Loss_D: 0.2898 Loss_G: 5.5907 D(x): 0.9621 D(G(z)): 1548.3727\n[53/400] Loss_D: 0.1639 Loss_G: 5.5114 D(x): 0.9746 D(G(z)): 344.9004\n[54/400] Loss_D: 0.1209 Loss_G: 6.2034 D(x): 0.9794 D(G(z)): 3500.2302\n[55/400] Loss_D: 0.2472 Loss_G: 5.8983 D(x): 0.9701 D(G(z)): 2644.6123\n[56/400] Loss_D: 0.1152 Loss_G: 5.9653 D(x): 0.9795 D(G(z)): 1274.4471\n[57/400] Loss_D: 0.2546 Loss_G: 6.3883 D(x): 0.9658 D(G(z)): 90904.3281\n[58/400] Loss_D: 0.2375 Loss_G: 5.7214 D(x): 0.9660 D(G(z)): 870.3253\n[59/400] Loss_D: 0.2572 Loss_G: 5.4869 D(x): 0.9593 D(G(z)): 1193.7291\n[60/400] Loss_D: 0.2264 Loss_G: 5.7262 D(x): 0.9643 D(G(z)): 840.0016\n[61/400] Loss_D: 0.1798 Loss_G: 6.1219 D(x): 0.9699 D(G(z)): 3458.2778\n[62/400] Loss_D: 0.1791 Loss_G: 6.2060 D(x): 0.9697 D(G(z)): 1802.4598\n[63/400] Loss_D: 0.2454 Loss_G: 5.6345 D(x): 0.9654 D(G(z)): 20705.4824\n[64/400] Loss_D: 0.2664 Loss_G: 5.1653 D(x): 0.9605 D(G(z)): 84.5043\n[65/400] Loss_D: 0.2166 Loss_G: 5.3657 D(x): 0.9644 D(G(z)): 370.2844\n[66/400] Loss_D: 0.0859 Loss_G: 6.0586 D(x): 0.9810 D(G(z)): 1029.5428\n[67/400] Loss_D: 0.1551 Loss_G: 6.2498 D(x): 0.9773 D(G(z)): 1685.1642\n[68/400] Loss_D: 0.1855 Loss_G: 5.9372 D(x): 0.9722 D(G(z)): 882.7364\n[69/400] Loss_D: 0.3191 Loss_G: 5.4374 D(x): 0.9596 D(G(z)): 4491.8184\n[70/400] Loss_D: 0.1710 Loss_G: 5.6092 D(x): 0.9709 D(G(z)): 684.0237\n[71/400] Loss_D: 0.1689 Loss_G: 6.2317 D(x): 0.9730 D(G(z)): 2741.2820\n[72/400] Loss_D: 0.2519 Loss_G: 5.6318 D(x): 0.9610 D(G(z)): 468.7682\n[73/400] Loss_D: 0.2344 Loss_G: 5.5878 D(x): 0.9647 D(G(z)): 710.5660\n[74/400] Loss_D: 0.2229 Loss_G: 5.6694 D(x): 0.9692 D(G(z)): 1763.0970\n[75/400] Loss_D: 0.0892 Loss_G: 5.3142 D(x): 0.9831 D(G(z)): 3.3482\n[76/400] Loss_D: 0.0600 Loss_G: 5.9292 D(x): 0.9875 D(G(z)): 13.3340\n[77/400] Loss_D: 0.0603 Loss_G: 5.8107 D(x): 0.9895 D(G(z)): 2.8067\n[78/400] Loss_D: 0.0807 Loss_G: 6.1465 D(x): 0.9847 D(G(z)): 193.4883\n[79/400] Loss_D: 0.0970 Loss_G: 5.9892 D(x): 0.9824 D(G(z)): 53.6546\n[80/400] Loss_D: 0.0443 Loss_G: 5.9422 D(x): 0.9903 D(G(z)): 18.1628\n[81/400] Loss_D: 0.0754 Loss_G: 6.3582 D(x): 0.9876 D(G(z)): 1333.2898\n[82/400] Loss_D: 0.0805 Loss_G: 6.5779 D(x): 0.9844 D(G(z)): 294.9742\n[83/400] Loss_D: 0.0665 Loss_G: 6.2513 D(x): 0.9877 D(G(z)): 561.8638\n[84/400] Loss_D: 0.0678 Loss_G: 6.3588 D(x): 0.9882 D(G(z)): 95.3233\n[85/400] Loss_D: 0.0563 Loss_G: 6.6161 D(x): 0.9889 D(G(z)): 422.6421\n[86/400] Loss_D: 0.0813 Loss_G: 6.5692 D(x): 0.9865 D(G(z)): 213.8215\n[87/400] Loss_D: 0.0924 Loss_G: 6.1831 D(x): 0.9847 D(G(z)): 600.4333\n[88/400] Loss_D: 0.0926 Loss_G: 6.5387 D(x): 0.9850 D(G(z)): 318.6620\n[89/400] Loss_D: 0.0438 Loss_G: 6.5998 D(x): 0.9903 D(G(z)): 39.0221\n[90/400] Loss_D: 0.0497 Loss_G: 6.7903 D(x): 0.9901 D(G(z)): 134.5353\n[91/400] Loss_D: 0.0637 Loss_G: 6.6410 D(x): 0.9889 D(G(z)): 822.9542\n[92/400] Loss_D: 0.1090 Loss_G: 6.6142 D(x): 0.9848 D(G(z)): 2428.3894\n[93/400] Loss_D: 0.0970 Loss_G: 6.2711 D(x): 0.9847 D(G(z)): 224.3259\n[94/400] Loss_D: 0.0946 Loss_G: 6.3503 D(x): 0.9841 D(G(z)): 279.4370\n[95/400] Loss_D: 0.0749 Loss_G: 6.3190 D(x): 0.9873 D(G(z)): 206.7066\n[96/400] Loss_D: 0.0603 Loss_G: 6.5522 D(x): 0.9885 D(G(z)): 433.4643\n[97/400] Loss_D: 0.0923 Loss_G: 6.4871 D(x): 0.9853 D(G(z)): 88.7718\n[98/400] Loss_D: 0.0510 Loss_G: 6.2330 D(x): 0.9893 D(G(z)): 110.2191\n[99/400] Loss_D: 0.0621 Loss_G: 6.7930 D(x): 0.9887 D(G(z)): 571.5509\n[100/400] Loss_D: 0.1207 Loss_G: 6.8256 D(x): 0.9839 D(G(z)): 393.9366\n[101/400] Loss_D: 0.0892 Loss_G: 6.6569 D(x): 0.9857 D(G(z)): 1169.1088\n[102/400] Loss_D: 0.0696 Loss_G: 6.2880 D(x): 0.9874 D(G(z)): 265.5580\n[103/400] Loss_D: 0.0713 Loss_G: 6.6442 D(x): 0.9897 D(G(z)): 362.1815\n[104/400] Loss_D: 0.0689 Loss_G: 6.6135 D(x): 0.9894 D(G(z)): 575.0270\n[105/400] Loss_D: 0.0722 Loss_G: 6.5801 D(x): 0.9890 D(G(z)): 296.9829\n[106/400] Loss_D: 0.0477 Loss_G: 6.9148 D(x): 0.9914 D(G(z)): 2037.1464\n[107/400] Loss_D: 0.1602 Loss_G: 6.7146 D(x): 0.9805 D(G(z)): 3458.6086\n[108/400] Loss_D: 0.0558 Loss_G: 6.3220 D(x): 0.9893 D(G(z)): 83.3444\n[109/400] Loss_D: 0.0516 Loss_G: 7.0705 D(x): 0.9911 D(G(z)): 5243.0039\n[110/400] Loss_D: 0.1129 Loss_G: 7.0710 D(x): 0.9844 D(G(z)): 1025.5338\n[111/400] Loss_D: 0.1011 Loss_G: 6.6277 D(x): 0.9820 D(G(z)): 68.1347\n[112/400] Loss_D: 0.0519 Loss_G: 6.1999 D(x): 0.9897 D(G(z)): 257.4089\n[113/400] Loss_D: 0.0529 Loss_G: 6.5458 D(x): 0.9897 D(G(z)): 207.9976\n[114/400] Loss_D: 0.0517 Loss_G: 6.8625 D(x): 0.9907 D(G(z)): 212.3389\n[115/400] Loss_D: 0.1197 Loss_G: 6.7168 D(x): 0.9843 D(G(z)): 16775.4863\n[116/400] Loss_D: 0.1243 Loss_G: 6.3663 D(x): 0.9820 D(G(z)): 424.4142\n[117/400] Loss_D: 0.0743 Loss_G: 6.2812 D(x): 0.9872 D(G(z)): 121.4511\n[118/400] Loss_D: 0.1433 Loss_G: 6.5355 D(x): 0.9786 D(G(z)): 439.8596\n[119/400] Loss_D: 0.0385 Loss_G: 6.4034 D(x): 0.9912 D(G(z)): 5.8661\n[120/400] Loss_D: 0.0395 Loss_G: 7.0210 D(x): 0.9917 D(G(z)): 2551.5759\n[121/400] Loss_D: 0.0409 Loss_G: 7.1361 D(x): 0.9919 D(G(z)): 3191.3049\n[122/400] Loss_D: 0.1121 Loss_G: 7.4053 D(x): 0.9844 D(G(z)): 1915.6119\n[123/400] Loss_D: 0.0911 Loss_G: 6.7848 D(x): 0.9869 D(G(z)): 860.6165\n[124/400] Loss_D: 0.0657 Loss_G: 6.8611 D(x): 0.9905 D(G(z)): 284.7722\n[125/400] Loss_D: 0.1114 Loss_G: 6.3618 D(x): 0.9832 D(G(z)): 330.9829\n[126/400] Loss_D: 0.0643 Loss_G: 6.6766 D(x): 0.9873 D(G(z)): 548.9708\n[127/400] Loss_D: 0.1167 Loss_G: 6.8300 D(x): 0.9816 D(G(z)): 6167.2354\n[128/400] Loss_D: 0.0865 Loss_G: 6.4273 D(x): 0.9857 D(G(z)): 206.7538\n[129/400] Loss_D: 0.0386 Loss_G: 6.6928 D(x): 0.9913 D(G(z)): 46.4093\n[130/400] Loss_D: 0.0591 Loss_G: 7.0144 D(x): 0.9880 D(G(z)): 246.6927\n[131/400] Loss_D: 0.0394 Loss_G: 6.8945 D(x): 0.9926 D(G(z)): 85.7584\n[132/400] Loss_D: 0.1094 Loss_G: 7.7045 D(x): 0.9832 D(G(z)): 9452.1748\n[133/400] Loss_D: 0.1011 Loss_G: 7.1444 D(x): 0.9814 D(G(z)): 3251.9211\n[134/400] Loss_D: 0.0863 Loss_G: 6.8950 D(x): 0.9863 D(G(z)): 309.7449\n[135/400] Loss_D: 0.0497 Loss_G: 6.7725 D(x): 0.9898 D(G(z)): 412.6530\n[136/400] Loss_D: 0.0493 Loss_G: 7.2545 D(x): 0.9916 D(G(z)): 11847.7900\n[137/400] Loss_D: 0.0700 Loss_G: 7.2586 D(x): 0.9902 D(G(z)): 84323.2812\n[138/400] Loss_D: 0.1167 Loss_G: 6.7258 D(x): 0.9854 D(G(z)): 1440.9006\n[139/400] Loss_D: 0.0998 Loss_G: 6.9217 D(x): 0.9864 D(G(z)): 349.0937\n[140/400] Loss_D: 0.1804 Loss_G: 6.4638 D(x): 0.9800 D(G(z)): 308.9001\n[141/400] Loss_D: 0.0909 Loss_G: 6.3324 D(x): 0.9850 D(G(z)): 157.9325\n[142/400] Loss_D: 0.0720 Loss_G: 7.0417 D(x): 0.9887 D(G(z)): 643.6286\n[143/400] Loss_D: 0.0446 Loss_G: 6.9840 D(x): 0.9913 D(G(z)): 1343.3571\n[144/400] Loss_D: 0.0936 Loss_G: 6.5981 D(x): 0.9860 D(G(z)): 310.7938\n[145/400] Loss_D: 0.0886 Loss_G: 6.5036 D(x): 0.9856 D(G(z)): 185.5121\n[146/400] Loss_D: 0.0465 Loss_G: 6.8333 D(x): 0.9905 D(G(z)): 126.1963\n[147/400] Loss_D: 0.0586 Loss_G: 7.3453 D(x): 0.9905 D(G(z)): 47181.7148\n[148/400] Loss_D: 0.0913 Loss_G: 7.3363 D(x): 0.9888 D(G(z)): 1350.2004\n[149/400] Loss_D: 0.0775 Loss_G: 6.7813 D(x): 0.9883 D(G(z)): 1530.6313\n[150/400] Loss_D: 0.0241 Loss_G: 6.6831 D(x): 0.9951 D(G(z)): 2.0541\n[151/400] Loss_D: 0.0371 Loss_G: 7.1251 D(x): 0.9934 D(G(z)): 13.4713\n[152/400] Loss_D: 0.0270 Loss_G: 7.5359 D(x): 0.9943 D(G(z)): 4.3537\n[153/400] Loss_D: 0.0242 Loss_G: 7.1419 D(x): 0.9947 D(G(z)): 4.7087\n[154/400] Loss_D: 0.0289 Loss_G: 7.4676 D(x): 0.9945 D(G(z)): 15.8268\n[155/400] Loss_D: 0.0778 Loss_G: 7.1506 D(x): 0.9875 D(G(z)): 63.4346\n[156/400] Loss_D: 0.0479 Loss_G: 7.3971 D(x): 0.9918 D(G(z)): 52.1945\n[157/400] Loss_D: 0.0265 Loss_G: 7.1401 D(x): 0.9956 D(G(z)): 3.0178\n[158/400] Loss_D: 0.0325 Loss_G: 6.8866 D(x): 0.9936 D(G(z)): 7.3659\n[159/400] Loss_D: 0.0417 Loss_G: 6.8793 D(x): 0.9933 D(G(z)): 29.7489\n[160/400] Loss_D: 0.0312 Loss_G: 7.0718 D(x): 0.9941 D(G(z)): 8.3676\n[161/400] Loss_D: 0.0265 Loss_G: 7.1571 D(x): 0.9947 D(G(z)): 43.2728\n[162/400] Loss_D: 0.0651 Loss_G: 6.9986 D(x): 0.9892 D(G(z)): 47.6804\n[163/400] Loss_D: 0.0267 Loss_G: 7.4547 D(x): 0.9951 D(G(z)): 10.7276\n[164/400] Loss_D: 0.0137 Loss_G: 7.0912 D(x): 0.9968 D(G(z)): 2.6978\n[165/400] Loss_D: 0.0098 Loss_G: 7.5768 D(x): 0.9977 D(G(z)): 1.5165\n[166/400] Loss_D: 0.0563 Loss_G: 7.1904 D(x): 0.9898 D(G(z)): 389.9796\n[167/400] Loss_D: 0.0225 Loss_G: 7.2185 D(x): 0.9956 D(G(z)): 28.4109\n[168/400] Loss_D: 0.0261 Loss_G: 7.7919 D(x): 0.9953 D(G(z)): 221.3000\n[169/400] Loss_D: 0.0242 Loss_G: 7.4579 D(x): 0.9948 D(G(z)): 167.0823\n[170/400] Loss_D: 0.0355 Loss_G: 7.7836 D(x): 0.9926 D(G(z)): 59.5599\n[171/400] Loss_D: 0.0217 Loss_G: 7.5671 D(x): 0.9965 D(G(z)): 58.7187\n[172/400] Loss_D: 0.0195 Loss_G: 7.5575 D(x): 0.9960 D(G(z)): 1291.2489\n[173/400] Loss_D: 0.0177 Loss_G: 8.2210 D(x): 0.9964 D(G(z)): 203.5337\n[174/400] Loss_D: 0.0904 Loss_G: 7.8176 D(x): 0.9898 D(G(z)): 141.3940\n[175/400] Loss_D: 0.0790 Loss_G: 6.4980 D(x): 0.9887 D(G(z)): 10.0023\n[176/400] Loss_D: 0.0338 Loss_G: 7.0846 D(x): 0.9940 D(G(z)): 12.8529\n[177/400] Loss_D: 0.0664 Loss_G: 7.0454 D(x): 0.9895 D(G(z)): 13.9903\n[178/400] Loss_D: 0.0373 Loss_G: 6.7831 D(x): 0.9934 D(G(z)): 13.9882\n[179/400] Loss_D: 0.0188 Loss_G: 7.1850 D(x): 0.9959 D(G(z)): 4.1794\n[180/400] Loss_D: 0.0270 Loss_G: 7.4857 D(x): 0.9949 D(G(z)): 13.0238\n[181/400] Loss_D: 0.0563 Loss_G: 7.4896 D(x): 0.9902 D(G(z)): 49.6778\n[182/400] Loss_D: 0.0509 Loss_G: 7.8362 D(x): 0.9927 D(G(z)): 12.6875\n[183/400] Loss_D: 0.0307 Loss_G: 6.9748 D(x): 0.9938 D(G(z)): 5.0910\n[184/400] Loss_D: 0.0408 Loss_G: 7.1236 D(x): 0.9939 D(G(z)): 9.9131\n[185/400] Loss_D: 0.0189 Loss_G: 7.5844 D(x): 0.9959 D(G(z)): 11.6643\n[186/400] Loss_D: 0.0445 Loss_G: 7.5973 D(x): 0.9936 D(G(z)): 153.4931\n[187/400] Loss_D: 0.0184 Loss_G: 7.4855 D(x): 0.9961 D(G(z)): 436.1897\n[188/400] Loss_D: 0.0618 Loss_G: 7.2898 D(x): 0.9918 D(G(z)): 17.2993\n[189/400] Loss_D: 0.0701 Loss_G: 7.3473 D(x): 0.9893 D(G(z)): 363.6993\n[190/400] Loss_D: 0.0204 Loss_G: 7.4768 D(x): 0.9960 D(G(z)): 12.2520\n[191/400] Loss_D: 0.0401 Loss_G: 7.1514 D(x): 0.9931 D(G(z)): 45.5924\n[192/400] Loss_D: 0.0358 Loss_G: 7.3347 D(x): 0.9928 D(G(z)): 23.7309\n[193/400] Loss_D: 0.0184 Loss_G: 7.5581 D(x): 0.9961 D(G(z)): 1.8920\n[194/400] Loss_D: 0.0367 Loss_G: 7.4671 D(x): 0.9943 D(G(z)): 25.2373\n[195/400] Loss_D: 0.0413 Loss_G: 7.0682 D(x): 0.9919 D(G(z)): 125.4433\n[196/400] Loss_D: 0.0949 Loss_G: 7.1522 D(x): 0.9880 D(G(z)): 10.0320\n[197/400] Loss_D: 0.0249 Loss_G: 6.7320 D(x): 0.9949 D(G(z)): 2.9116\n[198/400] Loss_D: 0.0578 Loss_G: 7.3359 D(x): 0.9903 D(G(z)): 15.4631\n[199/400] Loss_D: 0.0415 Loss_G: 7.3181 D(x): 0.9934 D(G(z)): 24.1971\n[200/400] Loss_D: 0.0249 Loss_G: 7.1873 D(x): 0.9951 D(G(z)): 14.2852\n[201/400] Loss_D: 0.0255 Loss_G: 6.7514 D(x): 0.9948 D(G(z)): 2.6954\n[202/400] Loss_D: 0.0545 Loss_G: 7.1848 D(x): 0.9912 D(G(z)): 9.6920\n[203/400] Loss_D: 0.0183 Loss_G: 7.5285 D(x): 0.9966 D(G(z)): 9.2367\n[204/400] Loss_D: 0.0379 Loss_G: 7.5919 D(x): 0.9934 D(G(z)): 132.3533\n[205/400] Loss_D: 0.0206 Loss_G: 7.6510 D(x): 0.9966 D(G(z)): 22.7004\n[206/400] Loss_D: 0.0337 Loss_G: 8.1038 D(x): 0.9937 D(G(z)): 88.4556\n[207/400] Loss_D: 0.0297 Loss_G: 8.2263 D(x): 0.9946 D(G(z)): 167.6012\n[208/400] Loss_D: 0.0233 Loss_G: 7.6500 D(x): 0.9950 D(G(z)): 3.9171\n[209/400] Loss_D: 0.0142 Loss_G: 7.7777 D(x): 0.9972 D(G(z)): 4.9827\n[210/400] Loss_D: 0.0649 Loss_G: 7.5980 D(x): 0.9910 D(G(z)): 181.3205\n[211/400] Loss_D: 0.0126 Loss_G: 7.6721 D(x): 0.9971 D(G(z)): 2.0573\n[212/400] Loss_D: 0.0243 Loss_G: 7.8196 D(x): 0.9951 D(G(z)): 50.7154\n[213/400] Loss_D: 0.0220 Loss_G: 8.0554 D(x): 0.9959 D(G(z)): 124.2796\n[214/400] Loss_D: 0.0229 Loss_G: 7.9128 D(x): 0.9957 D(G(z)): 16.6618\n[215/400] Loss_D: 0.0672 Loss_G: 7.7733 D(x): 0.9898 D(G(z)): 2856.2920\n[216/400] Loss_D: 0.0394 Loss_G: 7.2139 D(x): 0.9949 D(G(z)): 7.1668\n[217/400] Loss_D: 0.0178 Loss_G: 7.4915 D(x): 0.9962 D(G(z)): 3.8347\n[218/400] Loss_D: 0.0254 Loss_G: 8.7286 D(x): 0.9954 D(G(z)): 158.5462\n[219/400] Loss_D: 0.0865 Loss_G: 7.5759 D(x): 0.9888 D(G(z)): 71.0747\n[220/400] Loss_D: 0.0664 Loss_G: 7.3092 D(x): 0.9882 D(G(z)): 31.2712\n[221/400] Loss_D: 0.0437 Loss_G: 7.5782 D(x): 0.9919 D(G(z)): 8.6505\n[222/400] Loss_D: 0.0489 Loss_G: 7.2523 D(x): 0.9918 D(G(z)): 8.9419\n[223/400] Loss_D: 0.0178 Loss_G: 7.7764 D(x): 0.9963 D(G(z)): 4.3201\n[224/400] Loss_D: 0.0265 Loss_G: 7.8509 D(x): 0.9948 D(G(z)): 7.8372\n[225/400] Loss_D: 0.0186 Loss_G: 7.0969 D(x): 0.9964 D(G(z)): 1.4355\n[226/400] Loss_D: 0.0173 Loss_G: 7.2827 D(x): 0.9964 D(G(z)): 1.3664\n[227/400] Loss_D: 0.0177 Loss_G: 7.4595 D(x): 0.9961 D(G(z)): 1.4778\n[228/400] Loss_D: 0.0160 Loss_G: 7.8933 D(x): 0.9970 D(G(z)): 1.6903\n[229/400] Loss_D: 0.0127 Loss_G: 7.6615 D(x): 0.9965 D(G(z)): 1.7924\n[230/400] Loss_D: 0.0216 Loss_G: 7.4155 D(x): 0.9957 D(G(z)): 1.5527\n[231/400] Loss_D: 0.0126 Loss_G: 7.5283 D(x): 0.9974 D(G(z)): 1.2324\n[232/400] Loss_D: 0.0087 Loss_G: 7.8824 D(x): 0.9982 D(G(z)): 1.3191\n[233/400] Loss_D: 0.0208 Loss_G: 7.6002 D(x): 0.9958 D(G(z)): 50.8688\n[234/400] Loss_D: 0.0261 Loss_G: 7.7082 D(x): 0.9957 D(G(z)): 1.5623\n[235/400] Loss_D: 0.0105 Loss_G: 7.4615 D(x): 0.9978 D(G(z)): 1.1865\n[236/400] Loss_D: 0.0137 Loss_G: 7.8375 D(x): 0.9973 D(G(z)): 2.1029\n[237/400] Loss_D: 0.0233 Loss_G: 7.8721 D(x): 0.9957 D(G(z)): 6.2794\n[238/400] Loss_D: 0.0120 Loss_G: 8.0959 D(x): 0.9978 D(G(z)): 2.6221\n[239/400] Loss_D: 0.0094 Loss_G: 8.0804 D(x): 0.9980 D(G(z)): 1.2737\n[240/400] Loss_D: 0.0166 Loss_G: 8.8187 D(x): 0.9972 D(G(z)): 23.2186\n[241/400] Loss_D: 0.0339 Loss_G: 8.2673 D(x): 0.9942 D(G(z)): 23.8811\n[242/400] Loss_D: 0.0180 Loss_G: 7.7529 D(x): 0.9960 D(G(z)): 2.2340\n[243/400] Loss_D: 0.0102 Loss_G: 8.1428 D(x): 0.9976 D(G(z)): 1.3957\n[244/400] Loss_D: 0.0528 Loss_G: 7.8891 D(x): 0.9925 D(G(z)): 3.7250\n[245/400] Loss_D: 0.0177 Loss_G: 7.5215 D(x): 0.9968 D(G(z)): 1.3523\n[246/400] Loss_D: 0.0104 Loss_G: 7.9224 D(x): 0.9974 D(G(z)): 1.2515\n[247/400] Loss_D: 0.0112 Loss_G: 7.8819 D(x): 0.9979 D(G(z)): 4.3083\n[248/400] Loss_D: 0.0245 Loss_G: 7.8610 D(x): 0.9952 D(G(z)): 6.9729\n[249/400] Loss_D: 0.0126 Loss_G: 7.3052 D(x): 0.9977 D(G(z)): 1.3627\n[250/400] Loss_D: 0.0094 Loss_G: 8.0619 D(x): 0.9977 D(G(z)): 1.4280\n[251/400] Loss_D: 0.0268 Loss_G: 7.7603 D(x): 0.9957 D(G(z)): 10.4094\n[252/400] Loss_D: 0.0187 Loss_G: 7.4965 D(x): 0.9964 D(G(z)): 1.6170\n[253/400] Loss_D: 0.0206 Loss_G: 7.4037 D(x): 0.9964 D(G(z)): 2.6275\n[254/400] Loss_D: 0.0127 Loss_G: 7.9135 D(x): 0.9977 D(G(z)): 2.2975\n[255/400] Loss_D: 0.0165 Loss_G: 8.1481 D(x): 0.9970 D(G(z)): 1.8014\n[256/400] Loss_D: 0.0097 Loss_G: 8.2911 D(x): 0.9981 D(G(z)): 1.7168\n[257/400] Loss_D: 0.0239 Loss_G: 7.7402 D(x): 0.9955 D(G(z)): 5.5656\n[258/400] Loss_D: 0.0090 Loss_G: 8.4175 D(x): 0.9973 D(G(z)): 1.1254\n[259/400] Loss_D: 0.0173 Loss_G: 8.1656 D(x): 0.9972 D(G(z)): 10.5635\n[260/400] Loss_D: 0.0091 Loss_G: 7.8338 D(x): 0.9978 D(G(z)): 2.0904\n[261/400] Loss_D: 0.0256 Loss_G: 8.6193 D(x): 0.9955 D(G(z)): 7.3109\n[262/400] Loss_D: 0.0095 Loss_G: 7.7603 D(x): 0.9980 D(G(z)): 1.3328\n[263/400] Loss_D: 0.0312 Loss_G: 8.2432 D(x): 0.9943 D(G(z)): 32.8211\n[264/400] Loss_D: 0.0236 Loss_G: 7.8392 D(x): 0.9954 D(G(z)): 3.8494\n[265/400] Loss_D: 0.0203 Loss_G: 7.5667 D(x): 0.9959 D(G(z)): 2.8057\n[266/400] Loss_D: 0.0083 Loss_G: 8.3230 D(x): 0.9984 D(G(z)): 1.4750\n[267/400] Loss_D: 0.0214 Loss_G: 7.7651 D(x): 0.9958 D(G(z)): 1.6534\n[268/400] Loss_D: 0.0229 Loss_G: 8.2140 D(x): 0.9961 D(G(z)): 3.6717\n[269/400] Loss_D: 0.0160 Loss_G: 7.8947 D(x): 0.9961 D(G(z)): 1.6246\n[270/400] Loss_D: 0.0084 Loss_G: 7.9370 D(x): 0.9978 D(G(z)): 1.1535\n[271/400] Loss_D: 0.0096 Loss_G: 8.2680 D(x): 0.9978 D(G(z)): 1.5998\n[272/400] Loss_D: 0.0248 Loss_G: 7.9110 D(x): 0.9956 D(G(z)): 2.1569\n[273/400] Loss_D: 0.0079 Loss_G: 7.8049 D(x): 0.9984 D(G(z)): 1.1393\n[274/400] Loss_D: 0.0139 Loss_G: 7.9648 D(x): 0.9965 D(G(z)): 1.5021\n[275/400] Loss_D: 0.0132 Loss_G: 8.3939 D(x): 0.9973 D(G(z)): 2.3169\n[276/400] Loss_D: 0.0514 Loss_G: 7.5614 D(x): 0.9917 D(G(z)): 13.7773\n[277/400] Loss_D: 0.0056 Loss_G: 8.2191 D(x): 0.9989 D(G(z)): 1.1993\n[278/400] Loss_D: 0.0124 Loss_G: 7.8135 D(x): 0.9976 D(G(z)): 1.6009\n[279/400] Loss_D: 0.0213 Loss_G: 8.6576 D(x): 0.9957 D(G(z)): 28.4838\n[280/400] Loss_D: 0.0090 Loss_G: 8.4284 D(x): 0.9983 D(G(z)): 1.4203\n[281/400] Loss_D: 0.0134 Loss_G: 8.0962 D(x): 0.9968 D(G(z)): 1.4486\n[282/400] Loss_D: 0.0140 Loss_G: 8.0305 D(x): 0.9970 D(G(z)): 8.2331\n[283/400] Loss_D: 0.0377 Loss_G: 7.8026 D(x): 0.9944 D(G(z)): 8.1589\n[284/400] Loss_D: 0.0234 Loss_G: 8.0514 D(x): 0.9957 D(G(z)): 5.4156\n[285/400] Loss_D: 0.0079 Loss_G: 8.2987 D(x): 0.9981 D(G(z)): 1.1681\n[286/400] Loss_D: 0.0081 Loss_G: 8.6199 D(x): 0.9982 D(G(z)): 1.7040\n[287/400] Loss_D: 0.0103 Loss_G: 8.7536 D(x): 0.9984 D(G(z)): 160.1648\n[288/400] Loss_D: 0.0102 Loss_G: 8.4395 D(x): 0.9973 D(G(z)): 1.5772\n[289/400] Loss_D: 0.0414 Loss_G: 8.0950 D(x): 0.9941 D(G(z)): 8.3380\n[290/400] Loss_D: 0.0156 Loss_G: 8.2662 D(x): 0.9976 D(G(z)): 6.2913\n[291/400] Loss_D: 0.0379 Loss_G: 8.2224 D(x): 0.9944 D(G(z)): 2.3479\n[292/400] Loss_D: 0.0147 Loss_G: 7.5588 D(x): 0.9969 D(G(z)): 2.0815\n[293/400] Loss_D: 0.0105 Loss_G: 8.3806 D(x): 0.9978 D(G(z)): 1.3171\n[294/400] Loss_D: 0.0422 Loss_G: 7.7413 D(x): 0.9934 D(G(z)): 3.0894\n[295/400] Loss_D: 0.0103 Loss_G: 7.5091 D(x): 0.9984 D(G(z)): 1.2449\n[296/400] Loss_D: 0.0124 Loss_G: 7.9647 D(x): 0.9973 D(G(z)): 5.3969\n[297/400] Loss_D: 0.0167 Loss_G: 7.4923 D(x): 0.9959 D(G(z)): 1.4171\n[298/400] Loss_D: 0.0165 Loss_G: 8.8714 D(x): 0.9975 D(G(z)): 7.2820\n[299/400] Loss_D: 0.0216 Loss_G: 8.0709 D(x): 0.9959 D(G(z)): 6.5176\n[300/400] Loss_D: 0.0239 Loss_G: 7.1349 D(x): 0.9957 D(G(z)): 1.1120\n[301/400] Loss_D: 0.0149 Loss_G: 7.7277 D(x): 0.9971 D(G(z)): 1.0853\n[302/400] Loss_D: 0.0089 Loss_G: 7.6681 D(x): 0.9981 D(G(z)): 1.0470\n[303/400] Loss_D: 0.0060 Loss_G: 7.4621 D(x): 0.9987 D(G(z)): 1.0380\n[304/400] Loss_D: 0.0187 Loss_G: 7.7243 D(x): 0.9957 D(G(z)): 1.2387\n[305/400] Loss_D: 0.0198 Loss_G: 8.0604 D(x): 0.9959 D(G(z)): 1.2429\n[306/400] Loss_D: 0.0138 Loss_G: 8.1826 D(x): 0.9974 D(G(z)): 1.1051\n[307/400] Loss_D: 0.0072 Loss_G: 8.5409 D(x): 0.9985 D(G(z)): 1.1169\n[308/400] Loss_D: 0.0157 Loss_G: 8.1447 D(x): 0.9962 D(G(z)): 1.2512\n[309/400] Loss_D: 0.0070 Loss_G: 8.1974 D(x): 0.9982 D(G(z)): 1.1033\n[310/400] Loss_D: 0.0092 Loss_G: 7.9531 D(x): 0.9982 D(G(z)): 1.0888\n[311/400] Loss_D: 0.0087 Loss_G: 8.8407 D(x): 0.9980 D(G(z)): 1.1460\n[312/400] Loss_D: 0.0049 Loss_G: 8.8517 D(x): 0.9989 D(G(z)): 1.0536\n[313/400] Loss_D: 0.0047 Loss_G: 8.6033 D(x): 0.9990 D(G(z)): 1.0658\n[314/400] Loss_D: 0.0156 Loss_G: 7.8610 D(x): 0.9964 D(G(z)): 1.1801\n[315/400] Loss_D: 0.0139 Loss_G: 8.5046 D(x): 0.9975 D(G(z)): 1.4927\n[316/400] Loss_D: 0.0251 Loss_G: 8.4875 D(x): 0.9953 D(G(z)): 1.1539\n[317/400] Loss_D: 0.0100 Loss_G: 8.5394 D(x): 0.9980 D(G(z)): 1.1065\n[318/400] Loss_D: 0.0121 Loss_G: 8.3044 D(x): 0.9979 D(G(z)): 1.1993\n[319/400] Loss_D: 0.0088 Loss_G: 8.2079 D(x): 0.9979 D(G(z)): 1.0575\n[320/400] Loss_D: 0.0074 Loss_G: 8.5880 D(x): 0.9980 D(G(z)): 1.0794\n[321/400] Loss_D: 0.0100 Loss_G: 8.5091 D(x): 0.9978 D(G(z)): 1.2226\n[322/400] Loss_D: 0.0109 Loss_G: 8.5254 D(x): 0.9978 D(G(z)): 1.3261\n[323/400] Loss_D: 0.0062 Loss_G: 8.7193 D(x): 0.9988 D(G(z)): 1.0655\n[324/400] Loss_D: 0.0057 Loss_G: 8.3245 D(x): 0.9986 D(G(z)): 1.0698\n[325/400] Loss_D: 0.0148 Loss_G: 8.1578 D(x): 0.9974 D(G(z)): 1.2426\n[326/400] Loss_D: 0.0063 Loss_G: 8.2483 D(x): 0.9980 D(G(z)): 1.0533\n[327/400] Loss_D: 0.0117 Loss_G: 8.0109 D(x): 0.9972 D(G(z)): 1.1788\n[328/400] Loss_D: 0.0093 Loss_G: 7.9626 D(x): 0.9977 D(G(z)): 1.1699\n[329/400] Loss_D: 0.0059 Loss_G: 8.8046 D(x): 0.9986 D(G(z)): 1.2299\n[330/400] Loss_D: 0.0057 Loss_G: 8.5019 D(x): 0.9988 D(G(z)): 1.1699\n[331/400] Loss_D: 0.0312 Loss_G: 8.3548 D(x): 0.9935 D(G(z)): 3.4179\n[332/400] Loss_D: 0.0154 Loss_G: 7.9322 D(x): 0.9971 D(G(z)): 1.2177\n[333/400] Loss_D: 0.0106 Loss_G: 8.0256 D(x): 0.9975 D(G(z)): 1.0969\n[334/400] Loss_D: 0.0075 Loss_G: 8.4525 D(x): 0.9988 D(G(z)): 1.0703\n[335/400] Loss_D: 0.0082 Loss_G: 8.7157 D(x): 0.9977 D(G(z)): 1.0465\n[336/400] Loss_D: 0.0078 Loss_G: 8.3472 D(x): 0.9990 D(G(z)): 1.2211\n[337/400] Loss_D: 0.0069 Loss_G: 8.5536 D(x): 0.9980 D(G(z)): 1.1875\n[338/400] Loss_D: 0.0071 Loss_G: 8.3055 D(x): 0.9983 D(G(z)): 1.0990\n[339/400] Loss_D: 0.0151 Loss_G: 8.9336 D(x): 0.9975 D(G(z)): 1.7187\n[340/400] Loss_D: 0.0062 Loss_G: 8.5706 D(x): 0.9986 D(G(z)): 1.0875\n[341/400] Loss_D: 0.0289 Loss_G: 7.7350 D(x): 0.9946 D(G(z)): 1.4003\n[342/400] Loss_D: 0.0145 Loss_G: 8.7315 D(x): 0.9980 D(G(z)): 1.2437\n[343/400] Loss_D: 0.0073 Loss_G: 8.4569 D(x): 0.9986 D(G(z)): 1.0721\n[344/400] Loss_D: 0.0138 Loss_G: 8.1453 D(x): 0.9976 D(G(z)): 1.2930\n[345/400] Loss_D: 0.0051 Loss_G: 8.4400 D(x): 0.9987 D(G(z)): 1.0219\n[346/400] Loss_D: 0.0105 Loss_G: 8.4587 D(x): 0.9972 D(G(z)): 1.1707\n[347/400] Loss_D: 0.0114 Loss_G: 8.2866 D(x): 0.9974 D(G(z)): 1.1498\n[348/400] Loss_D: 0.0149 Loss_G: 7.9221 D(x): 0.9972 D(G(z)): 1.3571\n[349/400] Loss_D: 0.0075 Loss_G: 8.3297 D(x): 0.9982 D(G(z)): 1.1135\n[350/400] Loss_D: 0.0033 Loss_G: 8.8144 D(x): 0.9994 D(G(z)): 1.0372\n[351/400] Loss_D: 0.0111 Loss_G: 8.7454 D(x): 0.9973 D(G(z)): 1.1773\n[352/400] Loss_D: 0.0213 Loss_G: 8.6372 D(x): 0.9967 D(G(z)): 1.9320\n[353/400] Loss_D: 0.0153 Loss_G: 8.0252 D(x): 0.9969 D(G(z)): 1.1562\n[354/400] Loss_D: 0.0134 Loss_G: 7.7172 D(x): 0.9964 D(G(z)): 1.0965\n[355/400] Loss_D: 0.0095 Loss_G: 7.7573 D(x): 0.9976 D(G(z)): 1.1206\n[356/400] Loss_D: 0.0163 Loss_G: 7.9088 D(x): 0.9967 D(G(z)): 1.2094\n[357/400] Loss_D: 0.0232 Loss_G: 8.4358 D(x): 0.9957 D(G(z)): 1.2727\n[358/400] Loss_D: 0.0060 Loss_G: 8.3632 D(x): 0.9987 D(G(z)): 1.0485\n[359/400] Loss_D: 0.0164 Loss_G: 7.9683 D(x): 0.9966 D(G(z)): 1.1279\n[360/400] Loss_D: 0.0121 Loss_G: 7.8734 D(x): 0.9977 D(G(z)): 1.1150\n[361/400] Loss_D: 0.0119 Loss_G: 8.3033 D(x): 0.9967 D(G(z)): 1.1014\n[362/400] Loss_D: 0.0125 Loss_G: 8.7116 D(x): 0.9976 D(G(z)): 1.2318\n[363/400] Loss_D: 0.0058 Loss_G: 8.1991 D(x): 0.9986 D(G(z)): 1.0615\n[364/400] Loss_D: 0.0102 Loss_G: 7.9791 D(x): 0.9976 D(G(z)): 1.1607\n[365/400] Loss_D: 0.0069 Loss_G: 8.2349 D(x): 0.9983 D(G(z)): 1.1870\n[366/400] Loss_D: 0.0056 Loss_G: 9.2658 D(x): 0.9988 D(G(z)): 1.0863\n[367/400] Loss_D: 0.0029 Loss_G: 9.3143 D(x): 0.9995 D(G(z)): 1.0395\n[368/400] Loss_D: 0.0041 Loss_G: 9.1870 D(x): 0.9990 D(G(z)): 1.1645\n[369/400] Loss_D: 0.0040 Loss_G: 8.8320 D(x): 0.9992 D(G(z)): 1.2495\n[370/400] Loss_D: 0.0046 Loss_G: 9.2267 D(x): 0.9990 D(G(z)): 1.2834\n[371/400] Loss_D: 0.0333 Loss_G: 9.0665 D(x): 0.9944 D(G(z)): 1.9135\n[372/400] Loss_D: 0.0051 Loss_G: 8.0882 D(x): 0.9987 D(G(z)): 1.0409\n[373/400] Loss_D: 0.0240 Loss_G: 8.1078 D(x): 0.9959 D(G(z)): 1.1483\n[374/400] Loss_D: 0.0095 Loss_G: 8.0050 D(x): 0.9978 D(G(z)): 1.0734\n[375/400] Loss_D: 0.0046 Loss_G: 7.9703 D(x): 0.9992 D(G(z)): 1.0223\n[376/400] Loss_D: 0.0117 Loss_G: 7.7359 D(x): 0.9977 D(G(z)): 1.0359\n[377/400] Loss_D: 0.0052 Loss_G: 8.0772 D(x): 0.9988 D(G(z)): 1.0198\n[378/400] Loss_D: 0.0051 Loss_G: 8.2140 D(x): 0.9990 D(G(z)): 1.0283\n[379/400] Loss_D: 0.0094 Loss_G: 8.6867 D(x): 0.9981 D(G(z)): 1.0382\n[380/400] Loss_D: 0.0163 Loss_G: 8.2987 D(x): 0.9975 D(G(z)): 1.0885\n[381/400] Loss_D: 0.0089 Loss_G: 8.2941 D(x): 0.9977 D(G(z)): 1.0304\n[382/400] Loss_D: 0.0037 Loss_G: 8.0241 D(x): 0.9991 D(G(z)): 1.0154\n[383/400] Loss_D: 0.0070 Loss_G: 8.3945 D(x): 0.9989 D(G(z)): 1.0525\n[384/400] Loss_D: 0.0198 Loss_G: 7.7665 D(x): 0.9949 D(G(z)): 1.0562\n[385/400] Loss_D: 0.0202 Loss_G: 7.8647 D(x): 0.9960 D(G(z)): 1.0565\n[386/400] Loss_D: 0.0029 Loss_G: 8.8621 D(x): 0.9993 D(G(z)): 1.0094\n[387/400] Loss_D: 0.0051 Loss_G: 8.5756 D(x): 0.9987 D(G(z)): 1.0174\n[388/400] Loss_D: 0.0116 Loss_G: 8.1541 D(x): 0.9974 D(G(z)): 1.0345\n[389/400] Loss_D: 0.0059 Loss_G: 8.7275 D(x): 0.9985 D(G(z)): 1.0219\n[390/400] Loss_D: 0.0150 Loss_G: 7.8596 D(x): 0.9973 D(G(z)): 1.0523\n[391/400] Loss_D: 0.0207 Loss_G: 7.8107 D(x): 0.9958 D(G(z)): 1.0289\n[392/400] Loss_D: 0.0053 Loss_G: 8.5188 D(x): 0.9991 D(G(z)): 1.0157\n[393/400] Loss_D: 0.0029 Loss_G: 8.3276 D(x): 0.9994 D(G(z)): 1.0110\n[394/400] Loss_D: 0.0095 Loss_G: 8.2907 D(x): 0.9983 D(G(z)): 1.0441\n[395/400] Loss_D: 0.0059 Loss_G: 8.4982 D(x): 0.9985 D(G(z)): 1.0045\n[396/400] Loss_D: 0.0087 Loss_G: 7.7876 D(x): 0.9983 D(G(z)): 1.0437\n[397/400] Loss_D: 0.0038 Loss_G: 8.4240 D(x): 0.9992 D(G(z)): 1.0180\n[398/400] Loss_D: 0.0076 Loss_G: 7.8073 D(x): 0.9984 D(G(z)): 1.0335\n[399/400] Loss_D: 0.0045 Loss_G: 8.1783 D(x): 0.9988 D(G(z)): 1.0155\n[400/400] Loss_D: 0.0059 Loss_G: 8.4008 D(x): 0.9986 D(G(z)): 1.0320\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from IPython.display import FileLink\n\nos.chdir(r'/kaggle/working/')\n\n!tar -czf snapshots.tar.gz snapshots\n\nFileLink(r'snapshots.tar.gz')","metadata":{"execution":{"iopub.status.busy":"2023-03-21T07:37:07.331950Z","iopub.execute_input":"2023-03-21T07:37:07.332944Z","iopub.status.idle":"2023-03-21T07:37:12.332292Z","shell.execute_reply.started":"2023-03-21T07:37:07.332891Z","shell.execute_reply":"2023-03-21T07:37:12.331006Z"},"trusted":true},"execution_count":23,"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/snapshots.tar.gz","text/html":"<a href='snapshots.tar.gz' target='_blank'>snapshots.tar.gz</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"!tar -czf models.tar.gz models\n\nFileLink(r'models.tar.gz')","metadata":{"execution":{"iopub.status.busy":"2023-03-21T07:37:12.334411Z","iopub.execute_input":"2023-03-21T07:37:12.334818Z","iopub.status.idle":"2023-03-21T07:38:06.630913Z","shell.execute_reply.started":"2023-03-21T07:37:12.334762Z","shell.execute_reply":"2023-03-21T07:38:06.629635Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/models.tar.gz","text/html":"<a href='models.tar.gz' target='_blank'>models.tar.gz</a><br>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"code","source":"test_dataset = TextDataset(dataroot, dataroot2, transform=image_transform,split='test')","metadata":{"execution":{"iopub.status.busy":"2023-03-22T11:56:23.932725Z","iopub.execute_input":"2023-03-22T11:56:23.933780Z","iopub.status.idle":"2023-03-22T11:56:42.756424Z","shell.execute_reply.started":"2023-03-22T11:56:23.933722Z","shell.execute_reply":"2023-03-22T11:56:42.755251Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Total filenames:  11788 001.Black_footed_Albatross/Black_Footed_Albatross_0046_18.jpg\nLoad filenames from: /kaggle/input/birdsdata/test/filenames.pickle (3537)\nembeddings:  (3537, 10, 4800)\n","output_type":"stream"}]},{"cell_type":"code","source":"## Completed - TODO: Make a new DataLoader and Dataset to include embeddings\ntest_dataloader = torch.utils.data.DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=True,\n    num_workers=int(workers))","metadata":{"execution":{"iopub.status.busy":"2023-03-22T11:56:42.758987Z","iopub.execute_input":"2023-03-22T11:56:42.759688Z","iopub.status.idle":"2023-03-22T11:56:42.765630Z","shell.execute_reply.started":"2023-03-22T11:56:42.759646Z","shell.execute_reply":"2023-03-22T11:56:42.764461Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"file_path = './eval_results'\nif not os.path.exists(file_path):\n    os.makedirs(file_path)\n\nfor i, data in enumerate(test_dataloader, 0):\n    real_image, text_embedding,caption = data\n    batch_size = real_image.size(0)\n    text_embedding = Variable(text_embedding)\n\n    if cuda:\n        real_image = real_image.cuda()\n        text_embedding = text_embedding.cuda()\n\n    input.resize_as_(real_image).copy_(real_image)\n    inputv = Variable(input)\n\n    noise.resize_(batch_size, nz, 1, 1).normal_(0, 1)\n    noisev = Variable(noise)\n    num_test_outputs = 10\n\n    print(f\"Creating images for batch {i}\")\n    synthetic_image = netG(noisev, text_embedding)\n    synthetic_image = synthetic_image.detach()\n    \n    for y in range(synthetic_image.size()[0]):\n        \n        with open(f\"{file_path}/caption_{i+y}.txt\", \"w+\") as f:\n            f.write(caption[y])\n        \n        try:\n            vutils.save_image(synthetic_image[y].data,f\"{file_path}/{i+y}_image.jpg\")\n        except e:\n            print (e)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:00:42.920989Z","iopub.execute_input":"2023-03-22T12:00:42.921440Z","iopub.status.idle":"2023-03-22T12:01:09.703500Z","shell.execute_reply.started":"2023-03-22T12:00:42.921374Z","shell.execute_reply":"2023-03-22T12:01:09.702231Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Creating images for batch 0\nCreating images for batch 1\nCreating images for batch 2\nCreating images for batch 3\nCreating images for batch 4\nCreating images for batch 5\nCreating images for batch 6\nCreating images for batch 7\nCreating images for batch 8\nCreating images for batch 9\nCreating images for batch 10\nCreating images for batch 11\nCreating images for batch 12\nCreating images for batch 13\nCreating images for batch 14\nCreating images for batch 15\nCreating images for batch 16\nCreating images for batch 17\nCreating images for batch 18\nCreating images for batch 19\nCreating images for batch 20\nCreating images for batch 21\nCreating images for batch 22\nCreating images for batch 23\nCreating images for batch 24\nCreating images for batch 25\nCreating images for batch 26\nCreating images for batch 27\nCreating images for batch 28\nCreating images for batch 29\nCreating images for batch 30\nCreating images for batch 31\nCreating images for batch 32\nCreating images for batch 33\nCreating images for batch 34\nCreating images for batch 35\nCreating images for batch 36\nCreating images for batch 37\nCreating images for batch 38\nCreating images for batch 39\nCreating images for batch 40\nCreating images for batch 41\nCreating images for batch 42\nCreating images for batch 43\nCreating images for batch 44\nCreating images for batch 45\nCreating images for batch 46\nCreating images for batch 47\nCreating images for batch 48\nCreating images for batch 49\nCreating images for batch 50\nCreating images for batch 51\nCreating images for batch 52\nCreating images for batch 53\nCreating images for batch 54\nCreating images for batch 55\nCreating images for batch 56\nCreating images for batch 57\nCreating images for batch 58\nCreating images for batch 59\nCreating images for batch 60\nCreating images for batch 61\nCreating images for batch 62\nCreating images for batch 63\nCreating images for batch 64\nCreating images for batch 65\nCreating images for batch 66\nCreating images for batch 67\nCreating images for batch 68\nCreating images for batch 69\nCreating images for batch 70\nCreating images for batch 71\nCreating images for batch 72\nCreating images for batch 73\nCreating images for batch 74\nCreating images for batch 75\nCreating images for batch 76\nCreating images for batch 77\nCreating images for batch 78\nCreating images for batch 79\nCreating images for batch 80\nCreating images for batch 81\nCreating images for batch 82\nCreating images for batch 83\nCreating images for batch 84\nCreating images for batch 85\nCreating images for batch 86\nCreating images for batch 87\nCreating images for batch 88\nCreating images for batch 89\nCreating images for batch 90\nCreating images for batch 91\nCreating images for batch 92\nCreating images for batch 93\nCreating images for batch 94\nCreating images for batch 95\nCreating images for batch 96\nCreating images for batch 97\nCreating images for batch 98\nCreating images for batch 99\nCreating images for batch 100\nCreating images for batch 101\nCreating images for batch 102\nCreating images for batch 103\nCreating images for batch 104\nCreating images for batch 105\nCreating images for batch 106\nCreating images for batch 107\nCreating images for batch 108\nCreating images for batch 109\nCreating images for batch 110\n","output_type":"stream"}]},{"cell_type":"code","source":"from IPython.display import FileLink\n\nos.chdir(r'/kaggle/working/')\n\n!tar -czf eval_results.tar.gz eval_results\n\nFileLink(r'eval_results.tar.gz')","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:01:09.706151Z","iopub.execute_input":"2023-03-22T12:01:09.706503Z","iopub.status.idle":"2023-03-22T12:01:10.801693Z","shell.execute_reply.started":"2023-03-22T12:01:09.706469Z","shell.execute_reply":"2023-03-22T12:01:10.800445Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"/kaggle/working/eval_results.tar.gz","text/html":"<a href='eval_results.tar.gz' target='_blank'>eval_results.tar.gz</a><br>"},"metadata":{}}]},{"cell_type":"markdown","source":"# Inception score","metadata":{}},{"cell_type":"code","source":"# Code adapted from\n# https://github.com/openai/improved-gan/blob/master/inception_score/model.py\n# which was in turn derived from\n# tensorflow/tensorflow/models/image/imagenet/classify_image.py\n\n# Code from https://gist.github.com/jcjohnson/0779568bf0e4e64d141cae22414da549\nfrom __future__ import absolute_import\nfrom __future__ import division\nfrom __future__ import print_function\n\nimport os\nimport sys\nimport tarfile\n\nimport numpy as np\nfrom six.moves import urllib\nimport tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n# import tensorflow as tf\nimport glob\nfrom imageio import imread\nfrom skimage.transform import resize\nimport math\nimport sys","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:04:06.204275Z","iopub.execute_input":"2023-03-22T12:04:06.204873Z","iopub.status.idle":"2023-03-22T12:04:06.212938Z","shell.execute_reply.started":"2023-03-22T12:04:06.204831Z","shell.execute_reply":"2023-03-22T12:04:06.211722Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"input_image_dir  = '/kaggle/working/eval_results'\nnum_splits = 1\ntensor_layout = 'NHWC'\nIMAGE_EXTS = ['.png', '.jpg', '.jpeg']\n\n\nMODEL_DIR = '/tmp/imagenet'\nDATA_URL = 'http://download.tensorflow.org/models/image/imagenet/inception-2015-12-05.tgz'\nsoftmax = None\nimage_size = 64","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:04:08.607527Z","iopub.execute_input":"2023-03-22T12:04:08.608499Z","iopub.status.idle":"2023-03-22T12:04:08.614507Z","shell.execute_reply.started":"2023-03-22T12:04:08.608443Z","shell.execute_reply":"2023-03-22T12:04:08.613300Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"def load_images(image_dir):\n    print('Loading images from ', image_dir)\n    images = []\n    for fn in os.listdir(image_dir):\n        ext = os.path.splitext(fn)[1].lower()\n        if ext not in IMAGE_EXTS:\n            continue\n        img_path = os.path.join(image_dir, fn)\n        img = imread(img_path)\n        \n        if image_size is not None:\n            img = resize(img, (image_size, image_size))\n            img = img * 255.0\n        images.append(img)\n    print('Found %d images' % len(images))\n    return images\n\n\n# Call this function with list of images. Each of elements should be a \n# numpy array with values ranging from 0 to 255.\ndef get_inception_score(images):\n    splits = num_splits\n    layout = tensor_layout\n\n    assert(type(images) == list)\n    assert(type(images[0]) == np.ndarray)\n    assert(len(images[0].shape) == 3)\n    print(images[0].min(), images[0].max(), images[0].dtype)\n    assert(np.max(images[0]) > 10)\n    assert(np.min(images[0]) >= 0.0)\n    inps = []\n    for img in images:\n        img = img.astype(np.float32)\n        inps.append(np.expand_dims(img, 0))\n    bs = 100\n    with tf.Session() as sess:\n        preds = []\n        n_batches = int(math.ceil(float(len(inps)) / float(bs)))\n        n_preds = 0\n        for i in range(n_batches):\n            sys.stdout.write(\".\")\n            sys.stdout.flush()\n            inp = inps[(i * bs):min((i + 1) * bs, len(inps))]\n            inp = np.concatenate(inp, 0)\n            if layout == 'NCHW':\n                inp = inp.transpose(0, 2, 3, 1)\n            pred = sess.run(softmax, {'ExpandDims:0': inp})\n            preds.append(pred)\n            n_preds += pred.shape[0]\n            print('Ran %d / %d images' % (n_preds, len(images)))\n    preds = np.concatenate(preds, 0)\n    scores = []\n    for i in range(splits):\n        part = preds[(i * preds.shape[0] // splits):((i + 1) * preds.shape[0] // splits), :]\n        kl = part * (np.log(part) - np.log(np.expand_dims(np.mean(part, 0), 0)))\n        kl = np.mean(np.sum(kl, 1))\n        scores.append(np.exp(kl))\n    return np.mean(scores), np.std(scores)\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:04:10.778741Z","iopub.execute_input":"2023-03-22T12:04:10.779150Z","iopub.status.idle":"2023-03-22T12:04:10.797144Z","shell.execute_reply.started":"2023-03-22T12:04:10.779103Z","shell.execute_reply":"2023-03-22T12:04:10.795752Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"\n# This function is called automatically.\ndef _init_inception():\n    global softmax\n    if not os.path.exists(MODEL_DIR):\n        os.makedirs(MODEL_DIR)\n    filename = DATA_URL.split('/')[-1]\n    filepath = os.path.join(MODEL_DIR, filename)\n    if not os.path.exists(filepath):\n        def _progress(count, block_size, total_size):\n            sys.stdout.write('\\r>> Downloading %s %.1f%%' % (\n              filename, float(count * block_size) / float(total_size) * 100.0))\n            sys.stdout.flush()\n        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n        print()\n        statinfo = os.stat(filepath)\n        print('Succesfully downloaded', filename, statinfo.st_size, 'bytes.')\n    tarfile.open(filepath, 'r:gz').extractall(MODEL_DIR)\n    with tf.gfile.FastGFile(os.path.join(\n        MODEL_DIR, 'classify_image_graph_def.pb'), 'rb') as f:\n        graph_def = tf.GraphDef()\n        graph_def.ParseFromString(f.read())\n        _ = tf.import_graph_def(graph_def, name='')\n  # Works with an arbitrary minibatch size.\n    with tf.Session() as sess:\n        pool3 = sess.graph.get_tensor_by_name('pool_3:0')\n        ops = pool3.graph.get_operations()\n        for op_idx, op in enumerate(ops):\n            for o in op.outputs:\n                shape = o.get_shape()\n                shape = [s.value for s in shape]\n                new_shape = []\n                for j, s in enumerate(shape):\n                    if s == 1 and j == 0:\n                        new_shape.append(None)\n                    else:\n                        new_shape.append(s)\n                o.__dict__['_shape_val'] = tf.TensorShape(new_shape)\n                #o._shape = tf.TensorShape(new_shape)\n    w = sess.graph.get_operation_by_name(\"softmax/logits/MatMul\").inputs[1]\n    logits = tf.matmul(tf.squeeze(pool3,[1,2]), w)\n    #sslogits = tf.matmul(tf.squeeze(pool3), w)\n    softmax = tf.nn.softmax(logits)\n\n\nif softmax is None:\n    _init_inception()\n","metadata":{"execution":{"iopub.status.busy":"2023-03-22T11:57:27.336229Z","iopub.execute_input":"2023-03-22T11:57:27.336599Z","iopub.status.idle":"2023-03-22T11:57:44.369823Z","shell.execute_reply.started":"2023-03-22T11:57:27.336565Z","shell.execute_reply":"2023-03-22T11:57:44.368547Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":">> Downloading inception-2015-12-05.tgz 100.0%\nSuccesfully downloaded inception-2015-12-05.tgz 88931400 bytes.\n","output_type":"stream"}]},{"cell_type":"code","source":"\nimages = load_images(f\"{input_image_dir}\")\n\n#print(\"images.shape\")\n#sprint(images.shape)\nmean, std = get_inception_score(images)\nprint('Inception mean: ', mean)\nprint('Inception std: ', std)","metadata":{"execution":{"iopub.status.busy":"2023-03-22T12:04:20.722810Z","iopub.execute_input":"2023-03-22T12:04:20.723411Z","iopub.status.idle":"2023-03-22T12:04:22.155183Z","shell.execute_reply.started":"2023-03-22T12:04:20.723357Z","shell.execute_reply":"2023-03-22T12:04:22.152787Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"Loading images from  /kaggle/working/eval_results\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: DeprecationWarning: Starting with ImageIO v3 the behavior of this function will switch to that of iio.v3.imread. To keep the current behavior (and make this warning disappear) use `import imageio.v2 as imageio` or call `imageio.v2.imread` directly.\n  if __name__ == \"__main__\":\n","output_type":"stream"},{"name":"stdout","text":"Found 705 images\n0.0 255.0 float64\n.","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_23/216962694.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#print(\"images.shape\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#sprint(images.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_inception_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Inception mean: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Inception std: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/tmp/ipykernel_23/365030000.py\u001b[0m in \u001b[0;36mget_inception_score\u001b[0;34m(images)\u001b[0m\n\u001b[1;32m     45\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlayout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'NCHW'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'ExpandDims:0'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     48\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0mn_preds\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    967\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    968\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 969\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    970\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    971\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     \u001b[0;31m# Create a fetch handler to take care of the structure of fetches.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m     fetch_handler = _FetchHandler(\n\u001b[0;32m-> 1177\u001b[0;31m         self._graph, fetches, feed_dict_tensor, feed_handles=feed_handles)\n\u001b[0m\u001b[1;32m   1178\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m     \u001b[0;31m# Run request and get response.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, fetches, feeds, feed_handles)\u001b[0m\n\u001b[1;32m    483\u001b[0m     \"\"\"\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetch_mapper\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_FetchMapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfor_fetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mfor_fetch\u001b[0;34m(fetch)\u001b[0m\n\u001b[1;32m    260\u001b[0m     \"\"\"\n\u001b[1;32m    261\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfetch\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m       raise TypeError(f'Argument `fetch` = {fetch} has invalid type '\n\u001b[0m\u001b[1;32m    263\u001b[0m                       f'\"{type(fetch).__name__}\". Cannot be None')\n\u001b[1;32m    264\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: Argument `fetch` = None has invalid type \"NoneType\". Cannot be None"],"ename":"TypeError","evalue":"Argument `fetch` = None has invalid type \"NoneType\". Cannot be None","output_type":"error"}]},{"cell_type":"markdown","source":"# Inference","metadata":{}},{"cell_type":"code","source":"!wget http://www.cs.toronto.edu/~rkiros/models/dictionary.txt\n!wget http://www.cs.toronto.edu/~rkiros/models/utable.npy\n!wget http://www.cs.toronto.edu/~rkiros/models/btable.npy\n!wget http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz\n!wget http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz.pkl\n!wget http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz\n!wget http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz.pkl","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:54:48.489260Z","iopub.execute_input":"2023-04-09T03:54:48.489863Z","iopub.status.idle":"2023-04-09T03:57:10.350170Z","shell.execute_reply.started":"2023-04-09T03:54:48.489807Z","shell.execute_reply":"2023-04-09T03:57:10.349001Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"--2023-04-09 03:54:49--  http://www.cs.toronto.edu/~rkiros/models/dictionary.txt\nResolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\nConnecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 7996547 (7.6M) [text/plain]\nSaving to: dictionary.txt\n\ndictionary.txt      100%[===================>]   7.63M  10.8MB/s    in 0.7s    \n\n2023-04-09 03:54:50 (10.8 MB/s) - dictionary.txt saved [7996547/7996547]\n\n--2023-04-09 03:54:51--  http://www.cs.toronto.edu/~rkiros/models/utable.npy\nResolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\nConnecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2342138474 (2.2G)\nSaving to: utable.npy\n\nutable.npy          100%[===================>]   2.18G  43.0MB/s    in 52s     \n\n2023-04-09 03:55:44 (42.9 MB/s) - utable.npy saved [2342138474/2342138474]\n\n--2023-04-09 03:55:45--  http://www.cs.toronto.edu/~rkiros/models/btable.npy\nResolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\nConnecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 2342138474 (2.2G)\nSaving to: btable.npy\n\nbtable.npy          100%[===================>]   2.18G  40.6MB/s    in 53s     \n\n2023-04-09 03:56:38 (41.9 MB/s) - btable.npy saved [2342138474/2342138474]\n\n--2023-04-09 03:56:39--  http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz\nResolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\nConnecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 663989216 (633M)\nSaving to: uni_skip.npz\n\nuni_skip.npz        100%[===================>] 633.23M  47.3MB/s    in 19s     \n\n2023-04-09 03:57:00 (33.3 MB/s) - uni_skip.npz saved [663989216/663989216]\n\n--2023-04-09 03:57:01--  http://www.cs.toronto.edu/~rkiros/models/uni_skip.npz.pkl\nResolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\nConnecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 693\nSaving to: uni_skip.npz.pkl\n\nuni_skip.npz.pkl    100%[===================>]     693  --.-KB/s    in 0s      \n\n2023-04-09 03:57:01 (95.0 MB/s) - uni_skip.npz.pkl saved [693/693]\n\n--2023-04-09 03:57:02--  http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz\nResolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\nConnecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 289340074 (276M)\nSaving to: bi_skip.npz\n\nbi_skip.npz         100%[===================>] 275.94M  42.5MB/s    in 6.8s    \n\n2023-04-09 03:57:09 (40.4 MB/s) - bi_skip.npz saved [289340074/289340074]\n\n--2023-04-09 03:57:10--  http://www.cs.toronto.edu/~rkiros/models/bi_skip.npz.pkl\nResolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\nConnecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 689\nSaving to: bi_skip.npz.pkl\n\nbi_skip.npz.pkl     100%[===================>]     689  --.-KB/s    in 0s      \n\n2023-04-09 03:57:10 (88.5 MB/s) - bi_skip.npz.pkl saved [689/689]\n\n","output_type":"stream"}]},{"cell_type":"code","source":"!cp -r /kaggle/input/skipthoughts/* ./","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:57:57.872295Z","iopub.execute_input":"2023-04-09T03:57:57.873274Z","iopub.status.idle":"2023-04-09T03:57:58.926075Z","shell.execute_reply.started":"2023-04-09T03:57:57.873220Z","shell.execute_reply":"2023-04-09T03:57:58.924727Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"import skipthoughts\nimport numpy as np\nimport pickle\nimport os","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:58:19.146063Z","iopub.execute_input":"2023-04-09T03:58:19.147227Z","iopub.status.idle":"2023-04-09T03:58:21.421197Z","shell.execute_reply.started":"2023-04-09T03:58:19.147169Z","shell.execute_reply":"2023-04-09T03:58:21.420005Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"model = skipthoughts.load_model(path_to_models=\"/kaggle/working/\",\n                               path_to_tables=\"/kaggle/working/\")\nprint(\"Model loaded.\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T03:58:21.814939Z","iopub.execute_input":"2023-04-09T03:58:21.815282Z","iopub.status.idle":"2023-04-09T04:00:05.445335Z","shell.execute_reply.started":"2023-04-09T03:58:21.815250Z","shell.execute_reply":"2023-04-09T04:00:05.443920Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Loading model parameters...\nCompiling encoders...\nLoading tables...\nPacking up...\nModel loaded.\n","output_type":"stream"}]},{"cell_type":"code","source":"encoder = skipthoughts.Encoder(model)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T04:00:05.447785Z","iopub.execute_input":"2023-04-09T04:00:05.448560Z","iopub.status.idle":"2023-04-09T04:00:05.454235Z","shell.execute_reply.started":"2023-04-09T04:00:05.448518Z","shell.execute_reply":"2023-04-09T04:00:05.452898Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# this bird had a bright red head and belly with a short triangular beak and a black throat.\nsentence = [\"this bird is red with a short beak that curves down and black markings around its bill.\"]\n\nsent_embeddings = encoder.encode(sentence, verbose=False)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T04:33:12.132313Z","iopub.execute_input":"2023-04-09T04:33:12.133286Z","iopub.status.idle":"2023-04-09T04:33:12.605083Z","shell.execute_reply.started":"2023-04-09T04:33:12.133247Z","shell.execute_reply":"2023-04-09T04:33:12.603988Z"},"trusted":true},"execution_count":69,"outputs":[{"name":"stdout","text":"Preprocessing...\nPreprocess completed.\nRunning encoding...\n","output_type":"stream"},{"name":"stderr","text":"100%|| 1/1 [00:00<00:00,  7.46it/s]","output_type":"stream"},{"name":"stdout","text":"Encoding completed.\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"working_dir = \"/kaggle/working/\"\n\nsent_embeddings = torch.from_numpy(sent_embeddings)\nsent_embeddings = Variable(sent_embeddings)\n\nnz = 100\nnoise = torch.FloatTensor(1, nz, 1, 1)","metadata":{"execution":{"iopub.status.busy":"2023-04-09T04:33:12.606941Z","iopub.execute_input":"2023-04-09T04:33:12.608983Z","iopub.status.idle":"2023-04-09T04:33:12.614808Z","shell.execute_reply.started":"2023-04-09T04:33:12.608952Z","shell.execute_reply":"2023-04-09T04:33:12.613571Z"},"trusted":true},"execution_count":70,"outputs":[]},{"cell_type":"code","source":"noise.resize_(1, nz, 1, 1).normal_(0, 1)\nnoisev = Variable(noise)\n\nif cuda:\n    sent_embeddings = sent_embeddings.cuda()\n    noisev=noisev.cuda()\n\nsynthetic_image = netG(noisev, sent_embeddings)\nsynthetic_image = synthetic_image.detach()","metadata":{"execution":{"iopub.status.busy":"2023-04-09T04:33:12.866273Z","iopub.execute_input":"2023-04-09T04:33:12.866921Z","iopub.status.idle":"2023-04-09T04:33:12.878109Z","shell.execute_reply.started":"2023-04-09T04:33:12.866879Z","shell.execute_reply":"2023-04-09T04:33:12.877082Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"vutils.save_image(synthetic_image.data,f\"{working_dir}sample1.jpg\")","metadata":{"execution":{"iopub.status.busy":"2023-04-09T04:33:13.424087Z","iopub.execute_input":"2023-04-09T04:33:13.426817Z","iopub.status.idle":"2023-04-09T04:33:13.442330Z","shell.execute_reply.started":"2023-04-09T04:33:13.426775Z","shell.execute_reply":"2023-04-09T04:33:13.440594Z"},"trusted":true},"execution_count":72,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}